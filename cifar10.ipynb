{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "from torchmetrics.functional import pairwise_cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "cuda = torch.device(\"cuda:9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
    "#!unzip -q tiny-imagenet-200.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_parameters\n",
    "num_labels = 200\n",
    "input_shape = [3, 64, 64]\n",
    "num_train_data = 100000\n",
    "num_test_data = 10000\n",
    "batch_size = 50\n",
    "dataset_loc = './tiny-imagenet-200'\n",
    "dataset_name = 'tiny-imagenet-200'\n",
    "per_label_array = [10, 20, 30, 40, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 goldfish, Carassius auratus\n",
      "55 European fire salamander, Salamandra salamandra\n",
      "5 bullfrog, Rana catesbeiana\n",
      "183 tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui\n",
      "160 American alligator, Alligator mississipiensis\n",
      "177 boa constrictor, Constrictor constrictor\n",
      "174 trilobite\n",
      "125 scorpion\n",
      "141 black widow, Latrodectus mactans\n",
      "43 tarantula\n",
      "161 centipede\n",
      "67 goose\n",
      "68 koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus\n",
      "94 jellyfish\n",
      "164 brain coral\n",
      "33 snail\n",
      "100 slug\n",
      "165 sea slug, nudibranch\n",
      "151 American lobster, Northern lobster, Maine lobster, Homarus americanus\n",
      "89 spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish\n",
      "115 black stork, Ciconia nigra\n",
      "41 king penguin, Aptenodytes patagonica\n",
      "35 albatross, mollymawk\n",
      "116 dugong, Dugong dugon\n",
      "182 Chihuahua\n",
      "135 Yorkshire terrier\n",
      "78 golden retriever\n",
      "39 Labrador retriever\n",
      "11 German shepherd, German shepherd dog, German police dog, alsatian\n",
      "194 standard poodle\n",
      "66 tabby, tabby cat\n",
      "131 Persian cat\n",
      "0 Egyptian cat\n",
      "102 cougar, puma, catamount, mountain lion, painter, panther, Felis concolor\n",
      "184 lion, king of beasts, Panthera leo\n",
      "14 brown bear, bruin, Ursus arctos\n",
      "76 ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle\n",
      "113 fly\n",
      "87 bee\n",
      "180 grasshopper, hopper\n",
      "181 walking stick, walkingstick, stick insect\n",
      "48 cockroach, roach\n",
      "51 mantis, mantid\n",
      "105 dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\n",
      "13 monarch, monarch butterfly, milkweed butterfly, Danaus plexippus\n",
      "42 sulphur butterfly, sulfur butterfly\n",
      "37 sea cucumber, holothurian\n",
      "17 guinea pig, Cavia cobaya\n",
      "101 hog, pig, grunter, squealer, Sus scrofa\n",
      "120 ox\n",
      "175 bison\n",
      "158 bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis\n",
      "73 gazelle\n",
      "27 Arabian camel, dromedary, Camelus dromedarius\n",
      "159 orangutan, orang, orangutang, Pongo pygmaeus\n",
      "57 chimpanzee, chimp, Pan troglodytes\n",
      "32 baboon\n",
      "199 African elephant, Loxodonta africana\n",
      "44 lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens\n",
      "63 abacus\n",
      "74 academic gown, academic robe, judge's robe\n",
      "185 altar\n",
      "134 apron\n",
      "38 backpack, back pack, knapsack, packsack, rucksack, haversack\n",
      "189 bannister, banister, balustrade, balusters, handrail\n",
      "145 barbershop\n",
      "133 barn\n",
      "65 barrel, cask\n",
      "6 basketball\n",
      "179 bathtub, bathing tub, bath, tub\n",
      "147 beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
      "93 beacon, lighthouse, beacon light, pharos\n",
      "187 beaker\n",
      "50 beer bottle\n",
      "142 bikini, two-piece\n",
      "197 binoculars, field glasses, opera glasses\n",
      "72 birdhouse\n",
      "156 bow tie, bow-tie, bowtie\n",
      "155 brass, memorial tablet, plaque\n",
      "124 broom\n",
      "190 bucket, pail\n",
      "69 bullet train, bullet\n",
      "99 butcher shop, meat market\n",
      "84 candle, taper, wax light\n",
      "80 cannon\n",
      "31 cardigan\n",
      "106 cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM\n",
      "70 CD player\n",
      "171 chain\n",
      "110 chest\n",
      "123 Christmas stocking\n",
      "166 cliff dwelling\n",
      "26 computer keyboard, keypad\n",
      "146 confectionery, confectionary, candy store\n",
      "157 convertible\n",
      "103 crane\n",
      "88 dam, dike, dyke\n",
      "85 desk\n",
      "12 dining table, board\n",
      "153 drumstick\n",
      "154 dumbbell\n",
      "150 flagpole, flagstaff\n",
      "140 fountain\n",
      "52 freight car\n",
      "86 frying pan, frypan, skillet\n",
      "59 fur coat\n",
      "83 gasmask, respirator, gas helmet\n",
      "163 go-kart\n",
      "193 gondola\n",
      "24 hourglass\n",
      "91 iPod\n",
      "108 jinrikisha, ricksha, rickshaw\n",
      "172 kimono\n",
      "61 lampshade, lamp shade\n",
      "138 lawn mower, mower\n",
      "196 lifeboat\n",
      "114 limousine, limo\n",
      "191 magnetic compass\n",
      "21 maypole\n",
      "169 military uniform\n",
      "77 miniskirt, mini\n",
      "64 moving van\n",
      "29 nail\n",
      "81 neck brace\n",
      "186 obelisk\n",
      "20 oboe, hautboy, hautbois\n",
      "19 organ, pipe organ\n",
      "10 parking meter\n",
      "58 pay-phone, pay-station\n",
      "127 picket fence, paling\n",
      "98 pill bottle\n",
      "9 plunger, plumber's helper\n",
      "176 pole\n",
      "90 police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria\n",
      "178 poncho\n",
      "45 pop bottle, soda bottle\n",
      "96 potter's wheel\n",
      "49 projectile, missile\n",
      "92 punching bag, punch bag, punching ball, punchball\n",
      "1 reel\n",
      "132 refrigerator, icebox\n",
      "54 remote control, remote\n",
      "3 rocking chair, rocker\n",
      "128 rugby ball\n",
      "97 sandal\n",
      "15 school bus\n",
      "148 scoreboard\n",
      "129 sewing machine\n",
      "111 snorkel\n",
      "47 sock\n",
      "82 sombrero\n",
      "30 space heater\n",
      "36 spider web, spider's web\n",
      "117 sports car, sport car\n",
      "130 steel arch bridge\n",
      "137 stopwatch, stop watch\n",
      "112 sunglasses, dark glasses, shades\n",
      "119 suspension bridge\n",
      "136 swimming trunks, bathing trunks\n",
      "162 syringe\n",
      "71 teapot\n",
      "144 teddy, teddy bear\n",
      "139 thatch, thatched roof\n",
      "62 torch\n",
      "75 tractor\n",
      "79 triumphal arch\n",
      "152 trolleybus, trolley coach, trackless trolley\n",
      "122 turnstile\n",
      "18 umbrella\n",
      "104 vestment\n",
      "168 viaduct\n",
      "2 volleyball\n",
      "118 water jug\n",
      "109 water tower\n",
      "95 wok\n",
      "126 wooden spoon\n",
      "173 comic book\n",
      "143 plate\n",
      "53 guacamole\n",
      "28 ice cream, icecream\n",
      "121 ice lolly, lolly, lollipop, popsicle\n",
      "40 pretzel\n",
      "167 mashed potato\n",
      "198 cauliflower\n",
      "188 bell pepper\n",
      "107 mushroom\n",
      "149 orange\n",
      "4 lemon\n",
      "46 banana\n",
      "170 pomegranate\n",
      "192 meat loaf, meatloaf\n",
      "16 pizza, pizza pie\n",
      "23 potpie\n",
      "8 espresso\n",
      "60 alp\n",
      "7 cliff, drop, drop-off\n",
      "34 coral reef\n",
      "56 lakeside, lakeshore\n",
      "25 seashore, coast, seacoast, sea-coast\n",
      "195 acorn\n"
     ]
    }
   ],
   "source": [
    "id_dict = {}\n",
    "for i, line in enumerate(open(dataset_loc + \"/wnids.txt\", \"r\")):\n",
    "    id_dict[line.replace(\"\\n\", \"\")] = i\n",
    "\n",
    "label_dict = {}\n",
    "for i, line in enumerate(open(dataset_loc + \"/words.txt\", \"r\")):\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    n_id, word = line.split(\"\\t\")[:2]\n",
    "    if n_id in id_dict.keys():\n",
    "        label_id = id_dict[n_id]\n",
    "        label_dict[label_id] = word\n",
    "\n",
    "for label_id in label_dict.keys():\n",
    "    print(label_id, label_dict[label_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundup(x, base_index=1):\n",
    "    return math.ceil(x / pow(10, base_index)) * pow(10, base_index)\n",
    "\n",
    "\n",
    "def human_format(num):\n",
    "    num = float(\"{:.3g}\".format(num))\n",
    "    magnitude = 0\n",
    "    while abs(num) >= 1000:\n",
    "        magnitude += 1\n",
    "        num /= 1000.0\n",
    "    return \"{}{}\".format(\n",
    "        \"{:f}\".format(num).rstrip(\"0\").rstrip(\".\"), [\"\", \"K\", \"M\", \"B\", \"T\"][magnitude]\n",
    "    )\n",
    "\n",
    "\n",
    "def move_to_device(tensors, device):\n",
    "    if type(tensors) is tuple:\n",
    "        return tuple(tensor.to(device) for tensor in tensors)\n",
    "    return tensors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTinyImageNetDataset(Dataset):\n",
    "    def __init__(self, id, transform=None):\n",
    "        self.filenames = glob.glob(dataset_loc + \"/train/*/*/*.JPEG\")\n",
    "        self.transform = transform\n",
    "        self.id_dict = id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filenames[idx]\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if image.shape[0] == 1:\n",
    "            image = read_image(img_path, ImageReadMode.RGB)\n",
    "        label = self.id_dict[img_path.split(\"/\")[5].split(\"_\")[0]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image.type(torch.FloatTensor))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PartitionDataset(Dataset):\n",
    "    def __init__(self, location_str, label):\n",
    "        self.label = label\n",
    "        self.location_str = location_str\n",
    "        self.filename = location_str + str(label) + \".pt\"\n",
    "        data_tensor = torch.load(self.filename)\n",
    "        self.dataset_len = len(data_tensor)\n",
    "        del data_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_tensor = torch.load(self.filename)\n",
    "        return data_tensor[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestTinyImageNetDataset(Dataset):\n",
    "    def __init__(self, id, transform=None):\n",
    "        self.filenames = glob.glob(dataset_loc + \"/val/images/*.JPEG\")\n",
    "        self.transform = transform\n",
    "        self.id_dict = id\n",
    "        self.cls_dic = {}\n",
    "        for i, line in enumerate(open(dataset_loc + \"/val/val_annotations.txt\", \"r\")):\n",
    "            a = line.split(\"\\t\")\n",
    "            img, cls_id = a[0], a[1]\n",
    "            self.cls_dic[img] = self.id_dict[cls_id]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.filenames[idx]\n",
    "        image = read_image(img_path)\n",
    "\n",
    "        if image.shape[0] == 1:\n",
    "            image = read_image(img_path, ImageReadMode.RGB)\n",
    "        label = self.cls_dic[img_path.split(\"/\")[-1]]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image.type(torch.FloatTensor))\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    transform = transforms.Normalize(\n",
    "        (122.4786, 114.2755, 101.3963), (70.4924, 68.5679, 71.8127)\n",
    "    )\n",
    "\n",
    "    trainset = TrainTinyImageNetDataset(id=id_dict, transform=transform)\n",
    "    testset = TestTinyImageNetDataset(id=id_dict, transform=transform)\n",
    "    \n",
    "    train_images = torch.zeros([num_train_data] + input_shape)\n",
    "    train_labels = torch.ones(num_train_data)\n",
    "\n",
    "    test_images = torch.zeros([num_test_data] + input_shape)\n",
    "    test_labels = torch.ones(num_test_data)\n",
    "\n",
    "    for index in range(num_train_data):\n",
    "        train_images[index], train_labels[index] = trainset[index]\n",
    "\n",
    "    for index in range(num_test_data):\n",
    "        test_images[index], test_labels[index] = testset[index]\n",
    "    \n",
    "    del trainset, testset\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_class_partition(train_images, train_labels, test_images, test_labels):\n",
    "    train_image_partition = dict()\n",
    "    test_image_partition = dict()\n",
    "\n",
    "    for label in range(num_labels):\n",
    "        base_train_str = (\n",
    "            dataset_loc + \"/train/train_class_partition_\" + str(label) + \".pt\"\n",
    "        )\n",
    "        base_test_str = dataset_loc + \"/test/test_class_partition_\" + str(label) + \".pt\"\n",
    "\n",
    "        train_image_partition[label] = train_images[train_labels == label]\n",
    "        test_image_partition[label] = test_images[test_labels == label]\n",
    "\n",
    "        torch.save(train_image_partition[label], base_train_str)\n",
    "        torch.save(test_image_partition[label], base_test_str)\n",
    "\n",
    "\n",
    "def load_class_partition(label=None, train=True):\n",
    "    if train:\n",
    "        base_str = dataset_loc + \"/train/train_class_partition_\"\n",
    "    else:\n",
    "        base_str = dataset_loc + \"/test/test_class_partition_\"\n",
    "\n",
    "    if label is not None:\n",
    "        base_str += str(label) + \".pt\"\n",
    "        return torch.load(base_str, map_location='cpu')\n",
    "    else:\n",
    "        class_partition = dict()\n",
    "        for label in range(num_labels):\n",
    "            class_partition[label] = torch.load(\n",
    "                base_str + str(label) + \".pt\", map_location=\"cpu\"\n",
    "            )\n",
    "\n",
    "        return class_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images, labels, num_images=4):\n",
    "    assert len(images) == len(labels)\n",
    "    num_data = len(images)\n",
    "    start = torch.randint(0, num_data - num_images - 1, (1,)).item()\n",
    "\n",
    "    label_str = \"\"\n",
    "    for i in range(num_images):\n",
    "        label_str += label_dict[labels[start + i].item()] + \"\\n\"\n",
    "    print(label_str)\n",
    "\n",
    "    img_select = images[start : start + num_images]\n",
    "    for i in range(num_images):\n",
    "        img_min = img_select[i].min()\n",
    "        img_max = img_select[i].max()\n",
    "        img_select[i].clamp_(min=img_min, max=img_max)\n",
    "        img_select[i].add_(-img_min).div_(img_max - img_min + 1e-5)\n",
    "    img = torchvision.utils.make_grid(img_select, nrow=num_images)\n",
    "    \n",
    "    if img.is_cuda:\n",
    "        img = img.cpu()\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_images, train_labels, test_images, test_labels = load_data()\n",
    "\n",
    "#plot_images(train_images, train_labels)\n",
    "\n",
    "#plot_images(test_images, test_labels)\n",
    "\n",
    "#train_images, train_labels = move_to_device((train_images, train_labels), cuda)\n",
    "#test_images, test_labels = move_to_device((test_images, test_labels), cuda)\n",
    "#del train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_class_partition = load_class_partition(train=True)\n",
    "test_class_partition = load_class_partition(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_class_partition[0].get_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_greedy_subset_partition(domain, num_points):\n",
    "    domain = domain.to(device=cuda)\n",
    "    domain_flat = torch.flatten(domain, start_dim=1)\n",
    "\n",
    "    # flat_shape = domain_flat.shape[1:]\n",
    "    # subset_shape = [num_points, flat_shape]\n",
    "    subset_shape = [num_points] + input_shape\n",
    "\n",
    "    subset_domain = torch.zeros(subset_shape, device=cuda)\n",
    "    # random initialization\n",
    "    rand_index = torch.randint(0, len(domain), (1,)).item()\n",
    "    subset_domain[0] = domain[rand_index]\n",
    "\n",
    "    for index in range(1, num_points):\n",
    "        sim = pairwise_cosine_similarity(\n",
    "            domain_flat, torch.flatten(subset_domain[:index], start_dim=1)\n",
    "        )\n",
    "        max_sim = torch.max(sim, dim=1).values\n",
    "        selected_index = torch.argmin(max_sim).item()\n",
    "        subset_domain[index] = domain[selected_index]\n",
    "    return subset_domain\n",
    "\n",
    "\n",
    "def save_greedy_partition(image_partition, per_label, train=True):\n",
    "    dir_path = \"\"\n",
    "    if train:\n",
    "        dir_path += dataset_loc + \"/train\"\n",
    "    else:\n",
    "        dir_path += dataset_loc + \"/test\"\n",
    "    dir_path += \"/greedy\"\n",
    "    dir_path += \"/per_label_\" + str(per_label)\n",
    "    Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    file_path = \"/greedy_partition_\"\n",
    "\n",
    "    greedy_class_partition_first_half = dict()\n",
    "    greedy_class_partition_second_half = dict()\n",
    "\n",
    "    max_data_size = int(0.5 * per_label * 10)\n",
    "    half = int(0.5 * len(image_partition[0]))\n",
    "    assert max_data_size <= half\n",
    "\n",
    "    for label in range(num_labels):\n",
    "        if label % 10 == 0:\n",
    "            print(\"Finding greedy partition for label \" + str(label))\n",
    "\n",
    "        greedy_class_partition_first_half[label] = get_greedy_subset_partition(\n",
    "            image_partition[label][:max_data_size], per_label // 2\n",
    "        )\n",
    "        greedy_class_partition_second_half[label] = get_greedy_subset_partition(\n",
    "            image_partition[label][half : half + max_data_size], per_label // 2\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            greedy_class_partition_first_half[label],\n",
    "            dir_path + file_path + \"first_half_\" + str(label) + \".pt\",\n",
    "        )\n",
    "\n",
    "        torch.save(\n",
    "            greedy_class_partition_second_half[label],\n",
    "            dir_path + file_path + \"second_half_\" + str(label) + \".pt\",\n",
    "        )\n",
    "    return greedy_class_partition_first_half, greedy_class_partition_second_half\n",
    "\n",
    "\n",
    "def load_greedy_partition(per_label, label=None, train=True):\n",
    "    dir_path = \"\"\n",
    "    if train:\n",
    "        dir_path += dataset_loc + \"/train\"\n",
    "    else:\n",
    "        dir_path += dataset_loc + \"/test\"\n",
    "    dir_path += \"/greedy\"\n",
    "    dir_path += \"/per_label_\" + str(per_label)\n",
    "\n",
    "    file_path_first_half = \"/greedy_partition_first_half_\"\n",
    "    file_path_second_half = \"/greedy_partition_second_half_\"\n",
    "\n",
    "    if label is not None:\n",
    "        first_half = torch.load(\n",
    "            dir_path + file_path_first_half + str(label) + \".pt\", map_location=\"cpu\"\n",
    "        )\n",
    "        second_half = torch.load(\n",
    "            dir_path + file_path_second_half + str(label) + \".pt\", map_location=\"cpu\"\n",
    "        )\n",
    "        return first_half, second_half\n",
    "    else:\n",
    "        shape = [num_labels, per_label//2] + input_shape\n",
    "        class_partition_first_half = torch.zeros(shape)\n",
    "        class_partition_second_half = torch.zeros(shape)\n",
    "\n",
    "        for label in range(num_labels):\n",
    "            class_partition_first_half[label] = torch.load(\n",
    "                dir_path + file_path_first_half + str(label) + \".pt\",\n",
    "                map_location=\"cpu\"\n",
    "            )\n",
    "            class_partition_second_half[label] = torch.load(\n",
    "                dir_path + file_path_second_half + str(label) + \".pt\",\n",
    "                map_location=\"cpu\",\n",
    "            )\n",
    "\n",
    "        return class_partition_first_half, class_partition_second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for per_label in per_label_array:\n",
    "#    save_greedy_partition(train_class_partition, per_label=per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_trial_1, greedy_trial_2 = load_greedy_partition(30, label=0)\n",
    "\n",
    "print(greedy_trial_1.get_device())\n",
    "print(greedy_trial_1.shape)\n",
    "print(greedy_trial_2.get_device())\n",
    "print(greedy_trial_2.shape)\n",
    "\n",
    "del greedy_trial_1, greedy_trial_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_subsets_first_half = dict()\n",
    "greedy_subsets_second_half = dict() \n",
    "\n",
    "for per_label in per_label_array:\n",
    "    greedy_subsets_first_half[per_label], greedy_subsets_second_half[per_label] = load_greedy_partition(per_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_subsets_first_half[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_label in per_label_array:\n",
    "    greedy_subsets_first_half[per_label] = move_to_device(greedy_subsets_first_half[per_label], cuda)\n",
    "    greedy_subsets_second_half[per_label] = move_to_device(greedy_subsets_second_half[per_label], cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threat(reference_input, perturbations, threat_specification):\n",
    "    # assuming batch of flat inputs, perturbations and threats\n",
    "    unsafe_directions = -(reference_input.unsqueeze(1) - threat_specification)\n",
    "    # print(\"shape of unsafe direction is \" + str(unsafe_directions.shape))\n",
    "    \n",
    "    unsafe_norms = torch.linalg.norm(unsafe_directions, dim=2, ord=2)** 2\n",
    "    # print(\"shape of unsafe normalization is \" + str(unsafe_norms.shape))\n",
    "    \n",
    "    unsafe_directions = unsafe_directions / unsafe_norms.unsqueeze(-1)\n",
    "    \n",
    "    scaled_projections = torch.bmm(perturbations, unsafe_directions.permute(0, 2, 1))\n",
    "    threats = torch.max(scaled_projections, dim=2).values\n",
    "    #if threats.is_cuda:\n",
    "    #    threats = threats.cpu()\n",
    "    return threats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_threat(per_label_array, greedy=True, same_eval=False, step=10):\n",
    "    if not same_eval:\n",
    "        threat_first_half = torch.zeros(\n",
    "            len(per_label_array),\n",
    "            num_labels,\n",
    "            num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            device=cuda,\n",
    "        )\n",
    "        threat_second_half = torch.zeros(\n",
    "            len(per_label_array),\n",
    "            num_labels,\n",
    "            num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            device=cuda,\n",
    "        )\n",
    "    else:\n",
    "        threat_first_half = torch.zeros(\n",
    "            len(per_label_array),\n",
    "            num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            device=cuda,\n",
    "        )\n",
    "\n",
    "        threat_second_half = torch.zeros(\n",
    "            len(per_label_array),\n",
    "            num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            num_test_data // num_labels,\n",
    "            device=cuda,\n",
    "        )\n",
    "\n",
    "    # store a tensor threat of size num_labels, num_labels, test_per_label, test_per_label\n",
    "    # threat[i,j,k,l] = threat(x_{i_k}, x_{j_l})\n",
    "    # compute this threat[i,j] at a time.\n",
    "\n",
    "    for reference_label in range(num_labels):\n",
    "        # if reference_label > 0: break\n",
    "        print(\"At reference label \" + str(reference_label))\n",
    "\n",
    "        reference_input = move_to_device(test_class_partition[reference_label], cuda)\n",
    "        reference_input = torch.flatten(reference_input, start_dim=1)\n",
    "\n",
    "        for alt_label in range(num_labels):\n",
    "            if (alt_label == reference_label) and (not same_eval):\n",
    "                continue\n",
    "\n",
    "            if alt_label % 1 == 0:\n",
    "                print(\"At alt label \" + str(alt_label))\n",
    "\n",
    "            # if alt_label > 5: return  \n",
    "\n",
    "            alt_input = move_to_device(test_class_partition[alt_label], cuda)\n",
    "            alt_input = torch.flatten(alt_input, start_dim=1)\n",
    "            perturbations = -(reference_input.unsqueeze(1) - alt_input)\n",
    "            # print(\"Perturbation shape is \" + str(perturbations.shape))\n",
    "\n",
    "            for threat_label in range(0, num_labels, step):\n",
    "                label_list = torch.arange(threat_label, threat_label + step)\n",
    "\n",
    "                #if threat_label % 20 == 0:\n",
    "                #    print(\"At threat label \" + str(threat_label))\n",
    "\n",
    "                for (per_label_index, per_label) in enumerate(per_label_array):\n",
    "                    if greedy:\n",
    "                        threat_specification_first_half = move_to_device(\n",
    "                            greedy_subsets_first_half[per_label][\n",
    "                                label_list[label_list != reference_label]\n",
    "                            ],\n",
    "                            cuda,\n",
    "                        )\n",
    "                        threat_specification_second_half = move_to_device(\n",
    "                            greedy_subsets_second_half[per_label][\n",
    "                                label_list[label_list != reference_label]\n",
    "                            ],\n",
    "                            cuda,\n",
    "                        )\n",
    "                    \n",
    "                    threat_specification_first_half = torch.flatten(\n",
    "                        threat_specification_first_half, start_dim=2\n",
    "                    )\n",
    "                    dim1 = len(threat_specification_first_half)\n",
    "                    dim2 = per_label // 2\n",
    "                    dim3 = np.prod(input_shape)\n",
    "\n",
    "                    threat_specification_first_half = (\n",
    "                        threat_specification_first_half.view(dim1 * dim2, dim3)\n",
    "                    )\n",
    "\n",
    "                    threat_specification_second_half = torch.flatten(\n",
    "                        threat_specification_second_half, start_dim=2\n",
    "                    )\n",
    "\n",
    "                    threat_specification_second_half = (\n",
    "                        threat_specification_second_half.view(dim1 * dim2, dim3)\n",
    "                    )\n",
    "\n",
    "                    threat_first_half[\n",
    "                        per_label_index, reference_label, alt_label\n",
    "                    ] = torch.maximum(\n",
    "                        threat(\n",
    "                            reference_input,\n",
    "                            perturbations,\n",
    "                            threat_specification_first_half,\n",
    "                        ),\n",
    "                        threat_first_half[per_label_index, reference_label, alt_label],\n",
    "                    )\n",
    "\n",
    "                    threat_second_half[\n",
    "                        per_label_index, reference_label, alt_label\n",
    "                    ] = torch.maximum(\n",
    "                        threat(\n",
    "                            reference_input,\n",
    "                            perturbations,\n",
    "                            threat_specification_second_half,\n",
    "                        ),\n",
    "                        threat_second_half[per_label_index, reference_label, alt_label],\n",
    "                    )\n",
    "\n",
    "                    del (\n",
    "                        threat_specification_first_half,\n",
    "                        threat_specification_second_half,\n",
    "                    )\n",
    "\n",
    "            del alt_input\n",
    "            del perturbations\n",
    "\n",
    "        del reference_input\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return threat_first_half, threat_second_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_first_half, threat_second_half = eval_threat(per_label_array, greedy=True, same_eval=False, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_first_half = torch.randn(\n",
    "        len(per_label_array),\n",
    "        num_labels,\n",
    "        num_labels,\n",
    "        num_test_data // num_labels,\n",
    "        num_test_data // num_labels,\n",
    "        device=cuda,\n",
    "        )\n",
    "\n",
    "threat_second_half = torch.randn(\n",
    "        len(per_label_array),\n",
    "        num_labels,\n",
    "        num_labels,\n",
    "        num_test_data // num_labels,\n",
    "        num_test_data // num_labels,\n",
    "        device=cuda,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "threat_first_half -= torch.min(threat_first_half)\n",
    "threat_second_half -= torch.min(threat_second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_threat_statistics(threat_first_half, threat_second_half):\n",
    "    # threat_first_half\n",
    "    # threat_second_half\n",
    "    overall_threat = torch.maximum(threat_first_half, threat_second_half)\n",
    "    relative_diff = torch.abs(threat_first_half - threat_second_half).div(\n",
    "        overall_threat\n",
    "    )\n",
    "\n",
    "    min_threat = torch.zeros(\n",
    "        len(per_label_array), num_labels, num_test_data // num_labels, device='cpu'\n",
    "    )\n",
    "    label_list = torch.arange(0, num_labels)\n",
    "    for per_label_index in range(len(per_label_array)):\n",
    "        for reference_label in range(num_labels):\n",
    "            for index in range(num_test_data // num_labels):\n",
    "                min_threat[per_label_index, reference_label, index] = torch.min(\n",
    "                    torch.flatten(\n",
    "                        overall_threat[per_label_index, reference_label, label_list[label_list != reference_label], index, :],\n",
    "                        start_dim=0,\n",
    "                    )\n",
    "                ).item()\n",
    "\n",
    "    return overall_threat, relative_diff, min_threat\n",
    "    # later I can find misspecification rates based on the threat tensor.\n",
    "    # keep the large tensor threat on cpu always."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_threat, relative_diff, min_threat = compute_threat_statistics(threat_first_half, threat_second_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list = torch.arange(0, num_labels)\n",
    "num = len(torch.flatten(overall_threat[0,0,label_list[label_list != 0],:,:,],start_dim=0))\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_diff_flat = torch.zeros(len(per_label_array), num_labels, num, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_label_index in range(len(per_label_array)):\n",
    "    for label in range(num_labels):\n",
    "        relative_diff_flat = torch.flatten(\n",
    "            relative_diff[\n",
    "                per_label_index,\n",
    "                label,\n",
    "                label_list[label_list != label],\n",
    "                :,\n",
    "                :,\n",
    "            ],\n",
    "            start_dim=0,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_label_index in range(len(per_label_array)):\n",
    "    per_label = per_label_array[per_label_index]\n",
    "    print(\"For per-label - \" + str(per_label))\n",
    "    temp = torch.flatten(relative_diff_flat[per_label_index], start_dim=0)\n",
    "    print(torch.min(temp))\n",
    "    print(torch.max(temp))\n",
    "    print(torch.mean(temp))\n",
    "    plt.hist(temp.cpu(), bins=100, label=str(per_label))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_label_index in range(len(per_label_array)):\n",
    "    per_label = per_label_array[per_label_index]\n",
    "    print(\"For per-label - \" + str(per_label))\n",
    "    temp = torch.flatten(min_threat[per_label_index], start_dim=0).cpu()\n",
    "    print(temp.shape)\n",
    "    print(torch.min(temp))\n",
    "    print(torch.max(temp))\n",
    "    print(torch.mean(temp))\n",
    "    plt.figure()\n",
    "    plt.hist(temp, bins=10, label=str(per_label))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For per-label - 30\n",
      "torch.Size([10000])\n",
      "tensor(2.3130)\n",
      "tensor(4.2497)\n",
      "tensor(3.6678)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7d49b3439d90>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_label_index = 2\n",
    "per_label = per_label_array[per_label_index]\n",
    "print(\"For per-label - \" + str(per_label))\n",
    "temp = torch.flatten(min_threat[per_label_index], start_dim=0).cpu()\n",
    "print(temp.shape)\n",
    "print(torch.min(temp))\n",
    "print(torch.max(temp))\n",
    "print(torch.mean(temp))\n",
    "plt.hist(temp, bins=4, label=str(per_label))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7d49b1f86d00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cis/home/rmuthuk1/anaconda3/envs/advrob/lib/python3.9/site-packages/IPython/core/pylabtools.py:152: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(torch.randn(10000), bins=10, label=str(per_label))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_threat[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for per_label_index in range(len(per_label_array)):\n",
    "    torch.flatten(relative_diff, start_dim=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_threat():\n",
    "    for label1 in range(num_labels):\n",
    "        print(\"At label1 \" + str(label1))\n",
    "\n",
    "        # a = load_class_partition(train=False, label=label1)\n",
    "        a = test_class_partition[label1]\n",
    "        a = move_to_device(a, cuda)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        for label2 in range(num_labels):\n",
    "            if label2 == label1:\n",
    "                continue\n",
    "\n",
    "            # b = load_class_partition(train=False, label=label2)\n",
    "            b = test_class_partition[label2]\n",
    "            b = move_to_device(b, cuda)\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            for label3 in range(num_labels):\n",
    "                if label3 == label1:\n",
    "                    continue\n",
    "\n",
    "                # c = load_class_partition(train=True, label=label3)\n",
    "                c = train_class_partition[label3]\n",
    "                # c = load_class_partition(train=True, greedy=True, label=label3, num_points=5000)\n",
    "                # c = greedy_train_class_partition[label3]\n",
    "                c = move_to_device(c, cuda)\n",
    "\n",
    "                del c\n",
    "            del b\n",
    "        del a\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label1 in range(num_labels):\n",
    "    print(\"At label1 \" + str(label1))\n",
    "\n",
    "    # a = load_class_partition(train=False, label=label1)\n",
    "    a = test_class_partition[label1]\n",
    "    a = move_to_device(a, cuda)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    for label2 in range(num_labels):\n",
    "        if label2 == label1:\n",
    "            continue\n",
    "\n",
    "        # b = load_class_partition(train=False, label=label2)\n",
    "        b = test_class_partition[label2]\n",
    "        b = move_to_device(b, cuda)\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        for label3 in range(num_labels):\n",
    "            if label3 == label1:\n",
    "                continue\n",
    "\n",
    "            # c = load_class_partition(train=True, label=label3)\n",
    "            c = train_class_partition[label3]\n",
    "            # c = load_class_partition(train=True, greedy=True, label=label3, num_points=5000)\n",
    "            # c = greedy_train_class_partition[label3]\n",
    "            c = move_to_device(c, cuda)\n",
    "\n",
    "            del c\n",
    "        del b\n",
    "    del a\n",
    "    torch.cuda.empty_cache()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misspecification \n",
    "\n",
    "# threat comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for label in range(200):\n",
    "    #train_str = \"./tiny-imagenet-200/train/train_class_partition_\" + str(label) + \".pt\"\n",
    "    #test_str = \"./tiny-imagenet-200/test/test_class_partition_\" + str(label) + \".pt\"\n",
    "    #train_cp = torch.load(train_str)\n",
    "    #test_cp = torch.load(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_cp_loaders, test_cp_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = test_image_partition[13][0]\n",
    "\n",
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_image_partition[13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images in train_cp_loaders[10]:\n",
    "    images = move_to_device(images, cuda)\n",
    "    print(images.shape)\n",
    "    diff1 = input1.unsqueeze(0)\n",
    "    diff1 = images-input1\n",
    "    print(diff1.shape)\n",
    "    diff2 = torch.zeros_like(images)\n",
    "    for index in range(len(images)):\n",
    "        diff2[index] = images[index]-input1\n",
    "    \n",
    "    print(diff2.shape)\n",
    "\n",
    "    print(torch.linalg.norm(torch.flatten(diff1-diff2, start_dim=0), ord=2))\n",
    "    # so diff1 and diff2 are the same\n",
    "    diff1 = torch.flatten(diff1, start_dim=1)\n",
    "    print('flat shape is ' + str(diff1.shape))\n",
    "    norms = torch.linalg.norm(diff1, dim=1, ord=2)\n",
    "    print(norms.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = -0.5\n",
    "val = val * (val > 0)\n",
    "print(val)\n",
    "val < 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = 13\n",
    "label2 = 97\n",
    "label4 = 49\n",
    "input1 = torch.flatten(test_image_partition[label1],start_dim=1)\n",
    "print(input1.shape)\n",
    "input2 = torch.flatten(test_image_partition[label2], start_dim=1)\n",
    "input4 = torch.flatten(test_image_partition[label4], start_dim=1)\n",
    "print(input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(test_labels % 3 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_images[(test_labels != label1) * (test_labels % 3 == 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(4,100)\n",
    "b = torch.zeros(5,100)\n",
    "c = - (a.unsqueeze(1) - b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(c[2,3] - (a[2]-b[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbation = -(input1.unsqueeze(1) - input2)\n",
    "perturbation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainset = TrainTinyImageNetDataset(id=id_dict, transform=transform)\n",
    "#trainloader2 = torch.utils.data.DataLoader(trainset, batch_size=1024, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = 5\n",
    "    bel2 = 183\n",
    "cuda_new = torch.device(\"cuda:7\")\n",
    "input1 = torch.flatten(test_image_partition[label1], start_dim=1)\n",
    "input1 = input1.to(device=cuda_new)\n",
    "print(\"input1 shape is \" + str(input1.shape))\n",
    "input2 = torch.flatten(\n",
    "    test_images[(test_labels != label1) * (test_labels % 4 == 0)], start_dim=1\n",
    ")\n",
    "input2 = input2.to(device=cuda_new)\n",
    "print(\"input2 shape is \" + str(input2.shape))\n",
    "perturbation = -(input1.unsqueeze(1) - input2)\n",
    "print(\"perturbation shape is \" + str(perturbation.shape))\n",
    "# batch_distances = torch.zeros((len(input1), len(input2), 12), device=cuda)\n",
    "# print('batch_distances shape is ' +str(batch_distances.shape))\n",
    "max_distance = torch.zeros((len(input1), len(input2)), device=cuda_new)\n",
    "\n",
    "count = 0\n",
    "for label3 in range(200):\n",
    "    if label3 % 10 == 0:\n",
    "        print(\"Label3 is now \" + str(label3))\n",
    "    # if count > 0:    break\n",
    "    if label3 == label1:\n",
    "        continue\n",
    "    else:\n",
    "        images3 = move_to_device(\n",
    "            train_image_partition[label3], cuda_new\n",
    "        )  # train_image_partition[label3]\n",
    "        images3 = torch.flatten(images3, start_dim=1)\n",
    "        unsafe_directions = -(input1.unsqueeze(1) - images3)\n",
    "        # print(\"shape of unsafe direction is \" + str(unsafe_directions.shape))\n",
    "        unsafe_norms = torch.linalg.norm(unsafe_directions, dim=2, ord=2) ** 2\n",
    "        # print(\"shape of unsafe normalization is \" + str(unsafe_norms.shape))\n",
    "        unsafe_directions = unsafe_directions / unsafe_norms.unsqueeze(-1)\n",
    "\n",
    "        # print(\"\\nTrying approach 1\")\n",
    "        # print(perturbation.shape)\n",
    "        # print(unsafe_directions.shape)\n",
    "\n",
    "        # for index in range(len(input1)):\n",
    "        #    batch_distances = torch.matmul(\n",
    "        #        perturbation[index], unsafe_directions[index].T\n",
    "        #    )\n",
    "        #    max_distance[index] = torch.maximum(\n",
    "        #        max_distance[index], torch.max(batch_distances, dim=1).values\n",
    "        #    )\n",
    "        #    if index == -1:\n",
    "        #        print(\n",
    "        #            \"At each index, batch_distances shape is \"\n",
    "        #            + str(batch_distances.shape)\n",
    "        #        )\n",
    "        #        print(\"At each index, max_distance at index shape is \" + str(max_distance[index].shape))\n",
    "\n",
    "        # print(\"\\nTrying approach 2\")\n",
    "        # print(perturbation.shape)\n",
    "        # print(unsafe_directions.shape)\n",
    "        batch_distances = torch.bmm(perturbation, unsafe_directions.permute(0, 2, 1))\n",
    "        max_distance = torch.maximum(\n",
    "            torch.max(batch_distances, dim=2).values, max_distance\n",
    "        )\n",
    "        # print(batch_distances_2.shape)\n",
    "        # print('flattening')\n",
    "        # temp1 = torch.flatten(batch_distances, start_dim=0)\n",
    "        # print(temp1.shape)\n",
    "        # temp2 = torch.flatten(batch_distances_2, start_dim=0)\n",
    "        # print(temp2.shape)\n",
    "        # print(torch.linalg.norm(temp1-temp2, ord=1))\n",
    "        # del batch_distances, unsafe_directions, unsafe_norms, images3\n",
    "        count += 1\n",
    "\n",
    "# max_distance = torch.maximum(max_distance)\n",
    "# print(max_distance)\n",
    "# print(\"max distance until label \" + str(label3) + \" is \" + str(max_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I need multiple gpus lets say 5. \n",
    "- For each label gpu. \n",
    "\n",
    "measure misspecification and store the values. \n",
    "measure threat comparison, store the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del input1, input2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "300000*1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainset, testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(input1)\n",
    "max_distance = torch.zeros((len(input1), len(input2)), device=cuda)\n",
    "\n",
    "count = 0\n",
    "for label3 in range(200):\n",
    "    if label3 == label1:\n",
    "        continue\n",
    "    \n",
    "    if label3 % 10 == 0:\n",
    "        print('Label3 is now ' + str(label3))\n",
    "    #if count > 0: break \n",
    "\n",
    "    for images3 in train_cp_loaders[label3]:\n",
    "        images3 = move_to_device(images3, cuda)\n",
    "        images3 = torch.flatten(images3, start_dim=1)\n",
    "        unsafe_directions = -(input1.unsqueeze(1) - images3)\n",
    "        #print(unsafe_directions.shape)\n",
    "        unsafe_norms = torch.linalg.norm(unsafe_directions, dim=2, ord=2) ** 2\n",
    "        #print(unsafe_norms.shape)\n",
    "        unsafe_directions = unsafe_directions / unsafe_norms.unsqueeze(\n",
    "            -1\n",
    "        )  # torch.div(unsafe_directions, unsafe_norms)\n",
    "        #print(\"before matmul\")\n",
    "        #print(perturbation.shape)\n",
    "        #print(unsafe_directions.shape)\n",
    "        for index in range(len(input1)):\n",
    "            batch_distances = torch.matmul(perturbation[index], unsafe_directions[index].T)\n",
    "            #print(batch_distances.shape)\n",
    "            max_distance[index] = torch.maximum(max_distance[index], torch.max(batch_distances, dim=1).values)\n",
    "            #print(batch_max_distance.shape)\n",
    "            #print(batch_max_distance)\n",
    "            #max_distance[index] = batch_max_distance * (batch_max_distance > 0)\n",
    "            #print('the distances are now ')\n",
    "            #print(max_distance[index])\n",
    "        #print(\"did it work?\")\n",
    "        #batch_max_distance = torch.max(batch_distances).item()\n",
    "        #batch_max_distance = batch_max_distance * (batch_max_distance > 0)\n",
    "        #print(batch_max_distance)\n",
    "        #max_distance = max(batch_max_distance, max_distance)\n",
    "        count += 1\n",
    "\n",
    "print(max_distance)\n",
    "#print(\"max distance until label \" + str(label3) + \" is \" + str(max_distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_distance_ft = torch.min(max_distance, dim=1).values.cpu().numpy()\n",
    "\n",
    "np.shape(min_max_distance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_distance_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(min_max_distance_ft[min_max_distance_ft < 0.7])*100/len(min_max_distance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(min_max_distance_ft, bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_ft = torch.flatten(max_distance, start_dim=0).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_distance_ft[max_distance_ft < 0.7])*100/len(max_distance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2.16*2500/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(max_distance_ft, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_dict[89])\n",
    "print(label_dict[90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_distance_ft = torch.flatten(max_distance, start_dim=0).cpu().numpy()\n",
    "print(len(max_distance_ft[max_distance_ft < 1.0]) * 100 / len(max_distance_ft))\n",
    "plt.hist(max_distance_ft, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_distance_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(max_distance_ft[max_distance_ft < 0.6]) * 100 / len(max_distance_ft))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "label1 = 13\n",
    "label2 = 49\n",
    "\n",
    "for index1 in range(len(test_image_partition[label1])):\n",
    "    if count != 0:\n",
    "        break\n",
    "\n",
    "    input1 = test_image_partition[label1][index1]\n",
    "\n",
    "    for index2 in range(len(test_image_partition[label2])):\n",
    "        if count != 0:\n",
    "            break\n",
    "\n",
    "        input2 = test_image_partition[label2][index2]\n",
    "        perturbation = torch.flatten(input2 - input1, start_dim=0).T\n",
    "        print(\"Perturbation shape is \" + str(perturbation.shape))\n",
    "\n",
    "        max_distance = 0.0\n",
    "\n",
    "        for label3 in range(200):\n",
    "            # if count != 0:\n",
    "            #    break\n",
    "\n",
    "            if label3 == label1:\n",
    "                continue\n",
    "\n",
    "            for images3 in train_cp_loaders[label3]:\n",
    "                images3 = move_to_device(images3, cuda)\n",
    "                unsafe_directions = torch.flatten(\n",
    "                    images3 - input1.unsqueeze(0), start_dim=1\n",
    "                )\n",
    "                # print(unsafe_directions.shape)\n",
    "                unsafe_norms = torch.linalg.norm(unsafe_directions, dim=1, ord=2) ** 2\n",
    "                unsafe_directions = unsafe_directions / unsafe_norms.unsqueeze(\n",
    "                    -1\n",
    "                )  # torch.div(unsafe_directions, unsafe_norms)\n",
    "                # print(unsafe_directions.shape)\n",
    "                batch_distances = torch.matmul(unsafe_directions, perturbation)\n",
    "                batch_max_distance = torch.max(batch_distances).item()\n",
    "                batch_max_distance = batch_max_distance * (batch_max_distance > 0)\n",
    "                print(batch_max_distance)\n",
    "                max_distance = max(batch_max_distance, max_distance)\n",
    "                count += 1\n",
    "\n",
    "            print(\n",
    "                \"max distance until label \" + str(label3) + \" is \" + str(max_distance)\n",
    "            )\n",
    "\n",
    "\n",
    "# overall count should be 10000/50 x 10000/50 x 1000000/100 : 10^4 x 10^4 x 10^6 / 100*2500 = 10^14 / (10^4 x 25) = 10^10/25 = 10^9/2.5 = 4 x 10^8\n",
    "# 4 x 10^8/10^3 = 400,000\n",
    "# for images, labels in testloader:\n",
    "#    if count != 0 and count % 1e3 == 0:\n",
    "#        break\n",
    "#    for images2, labels2 in testloader:\n",
    "#        for label3 in range(200):\n",
    "#            for images3 in train_cp_loaders[label3]:\n",
    "#                # unsafe_directions = images3-images1\n",
    "#                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cp_loaders[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "# create max distance array of 200 x 50 x 200 x 50 nah this is 100million\n",
    "for label1 in range(200):\n",
    "    print(\"Label1 is at \" + str(label1))\n",
    "\n",
    "    for images1 in test_cp_loaders[label1]:\n",
    "        # shape of images 1 is 50*3*64*64\n",
    "        # maintain max_distance for each image 50*1\n",
    "\n",
    "        for label2 in range(200):\n",
    "            if label2 == label1:\n",
    "                continue\n",
    "\n",
    "            for images2 in test_cp_loaders[label2]:\n",
    "                # shape of images 2 is 50x3x64x64\n",
    "\n",
    "                perturbation = torch.flatten(images2 - images1, start_dim=0)\n",
    "\n",
    "                # i need perturbations to be a tensor of size num(images1) x num(images2) x 3 x 64 x 64\n",
    "                # so perturbations[i,j] is the difference between images2[j] - images1[i]\n",
    "                # flatten perturbations so that perturbations[i,j] is 12288 length 1D tensor \n",
    "                # now for each of these perturbations the source image had label - label1. \n",
    "                # i need perturbations to be a tensor of size 50 x 50 x 3 x 64 x 64 that's 30 million!\n",
    "\n",
    "                for label3 in range(200):\n",
    "                    if label3 == label1:\n",
    "                        continue\n",
    "\n",
    "                    for images3 in train_cp_loaders[label3]:\n",
    "                        unsafe_directions = torch.flatten(images3-images1, start_dim=\n",
    "                        norm_diff = torch.linalg.norm(unsafe_directions)\n",
    "                        u_index = (label//int(label_stride)) * per_label + index\n",
    "                        input = selected_domain[label][index]\n",
    "                        norm_diff = float(\"inf\")\n",
    "                        norm_diff = torch.linalg.norm(torch.flatten(input - reference_input, start_dim=0), ord=2)** 2\n",
    "                        unsafe_dirs[u_index] = (input - reference_input) / norm_diff\n",
    "                        unsafe_normalization[index] = torch.sqrt(norm_diff)\n",
    "\n",
    "\n",
    "                        # i need unsafe directions of num(images1) x num(images3) x 3 x 64 x 64\n",
    "                        # so unsafe[i,k] is the difference between images3[k] - images1[i]\n",
    "                        # flatten unsafe so that unsafe[i,k] is 12288 length 1D tensor\n",
    "                        # create distance matrix out of perturbations[i,j] unsafe[i,k]\n",
    "                        count += 1\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 89\n",
    "num = 4\n",
    "base = torch.randint(0, 500-num-1, (1,)).item()\n",
    "img_select = train_image_partition[label][base:base+num]\n",
    "for i in range(num):\n",
    "    img_min = img_select[i].min()\n",
    "    img_max = img_select[i].max()\n",
    "    img_select[i].clamp_(min=img_min, max=img_max)\n",
    "    img_select[i].add_(-img_min).div_(img_max - img_min + 1e-5)\n",
    "img = torchvision.utils.make_grid(img_select, nrow=num)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 89\n",
    "num = 4\n",
    "base = torch.randint(0, 50 - num - 1, (1,)).item()\n",
    "#print(base)\n",
    "#print(base + num)\n",
    "#print(len(test_image_partition[label][base : base + num]))\n",
    "img_select = test_image_partition[label][base : base + num]\n",
    "#print(img_select.shape)\n",
    "for i in range(num):\n",
    "    img_min = img_select[i].min()\n",
    "    img_max = img_select[i].max()\n",
    "    img_select[i].clamp_(min=img_min, max=img_max)\n",
    "    img_select[i].add_(-img_min).div_(img_max - img_min + 1e-5)\n",
    "img = torchvision.utils.make_grid(img_select, nrow=num)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_greedy_subset_partition(domain, num_points):\n",
    "    #print(list(domain.size()))\n",
    "    inp_shape = list(domain.shape)[1:]\n",
    "    subset_shape = [num_points] + inp_shape\n",
    "    rand_index = torch.randint(0,len(domain), (1,)).item()\n",
    "    subset_domain = torch.zeros(subset_shape, device=cuda)\n",
    "    subset_labels = torch.zeros(num_points, dtype=torch.int64, device=cuda)\n",
    "    subset_domain[0] = domain[rand_index]\n",
    "    \n",
    "    domain_flat = torch.flatten(domain, start_dim=1)\n",
    "    for index in range(1, num_points):\n",
    "        sim = pairwise_cosine_similarity(domain_flat, torch.flatten(subset_domain[:index], start_dim=1))\n",
    "        max_sim = torch.max(sim, dim=1).values\n",
    "        selected_index = torch.argmin(max_sim).item()\n",
    "        subset_domain[index] = domain[selected_index]\n",
    "    return subset_domain   \n",
    "\n",
    "def get_greedy_class_subset(domain_partition, num_points):\n",
    "    greedy_train_image_partition = dict()\n",
    "    for label in range(200):\n",
    "        if label%50 == 0:\n",
    "            print('Finding greedy partition for label ' + str(label))\n",
    "        greedy_train_image_partition[label] = get_greedy_subset_partition(domain_partition[label], num_points//200)\n",
    "    return greedy_train_image_partition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_image_partition[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unsafe_dir(reference_input, reference_label, selected_domain, beta=1.0, label_stride=None):\n",
    "    per_label = len(selected_domain[0])\n",
    "    num_labels = len(selected_domain)\n",
    "    #print(\"Inside compute unsafe and number of labels is \" + str(num_labels))\n",
    "    num = num_labels * per_label #+ 1 \n",
    "    inp_shape = list(reference_input.shape)\n",
    "\n",
    "    unsafe_dirs = torch.zeros([num] + inp_shape, device=cuda)\n",
    "    unsafe_normalization = torch.ones(num, device=cuda) * float(\"inf\")\n",
    "\n",
    "    for label in range(200):\n",
    "        if label_stride is not None and label % int(label_stride) != 0:\n",
    "            continue\n",
    "\n",
    "        for index in range(per_label):\n",
    "            u_index = (label//int(label_stride)) * per_label + index\n",
    "            input = selected_domain[label][index]\n",
    "            norm_diff = float(\"inf\")\n",
    "            if label != reference_label:\n",
    "                norm_diff = (\n",
    "                    beta\n",
    "                    * torch.linalg.norm(\n",
    "                        torch.flatten(input - reference_input, start_dim=0), ord=2\n",
    "                    )\n",
    "                    ** 2\n",
    "                )\n",
    "                unsafe_dirs[u_index] = (input - reference_input) / norm_diff\n",
    "                unsafe_normalization[index] = torch.sqrt(norm_diff)\n",
    "\n",
    "    #ref_norm = (\n",
    "    #    torch.linalg.norm(torch.flatten(reference_input, start_dim=0), ord=2) ** 2\n",
    "    #)\n",
    "    #unsafe_dirs[-1] = -reference_input / ref_norm\n",
    "    #unsafe_normalization[-1] = torch.sqrt(ref_norm)\n",
    "\n",
    "    return unsafe_dirs, unsafe_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_threats(data_size, domain, test_domain, label_stride=None):\n",
    "    print(\"Label stride is \" + str(label_stride))\n",
    "    num_label = len(domain)\n",
    "    per_label = len(domain[0])\n",
    "    half_per_label = int(0.5 * per_label)\n",
    "    data_per_label = data_size // num_label\n",
    "    print(\"Data per label is \" + str(data_per_label))\n",
    "    assert data_per_label < int(half_per_label)\n",
    "\n",
    "    test_per_label = len(test_domain[0])\n",
    "\n",
    "    domain_first_half = dict()\n",
    "    domain_second_half = dict()\n",
    "\n",
    "    random_index = 0  # torch.randint(0, half_per_label - data_per_label, (1,)).item()\n",
    "\n",
    "    active_labels = []\n",
    "    for label in range(num_label):\n",
    "        if label_stride is not None and label % int(label_stride) == 0:\n",
    "            active_labels.append(label)\n",
    "    print(\"Active labels are \")\n",
    "    print(active_labels)\n",
    "\n",
    "    for label in range(num_label):\n",
    "        if label_stride is not None and label % int(label_stride) != 0:\n",
    "            continue\n",
    "\n",
    "        domain_first_half[label] = domain[label][\n",
    "            random_index : random_index + data_per_label\n",
    "        ]\n",
    "        domain_second_half[label] = domain[label][\n",
    "            half_per_label\n",
    "            + random_index : half_per_label\n",
    "            + random_index\n",
    "            + data_per_label\n",
    "        ]\n",
    "\n",
    "    # subset_first_half = get_greedy_class_subset(domain_first_half, data_size//2)\n",
    "    # subset_second_half = get_greedy_class_subset(domain_second_half, data_size//2)\n",
    "\n",
    "    all_overall_diff = []\n",
    "    count = 0\n",
    "    overall_diff = 0.0\n",
    "    max_diff = 0.0\n",
    "    avg_threat = 0.0\n",
    "    all_threat_first_half = []\n",
    "    all_threat_second_half = []\n",
    "\n",
    "    for label_1 in range(num_label):\n",
    "        if label_stride is not None and label_1 % int(label_stride) != 0:\n",
    "            continue\n",
    "\n",
    "        # print(\"evaluating threats for label_1 \" + str(label_1))\n",
    "\n",
    "        for index_1 in range(test_per_label):\n",
    "            # if label_1 % 50 == 0 and index_1 % 10 == 0: print('evaluating threats for index_1 ' + str(index_1))\n",
    "            input_1 = test_domain[label_1][index_1]\n",
    "            (\n",
    "                unsafe_dirs_first_half,\n",
    "                _\n",
    "            ) = compute_unsafe_dir(\n",
    "                input_1, label_1, domain_first_half, beta=1.0, label_stride=label_stride\n",
    "            )\n",
    "            (\n",
    "                unsafe_dirs_second_half,\n",
    "                _\n",
    "            ) = compute_unsafe_dir(\n",
    "                input_1,\n",
    "                label_1,\n",
    "                domain_second_half,\n",
    "                beta=1.0,\n",
    "                label_stride=label_stride,\n",
    "            )\n",
    "\n",
    "            unsafe_ft_first_half = torch.flatten(unsafe_dirs_first_half, start_dim=1)\n",
    "            unsafe_ft_second_half = torch.flatten(unsafe_dirs_second_half, start_dim=1)\n",
    "\n",
    "            for label_2 in range(num_label):\n",
    "                if label_1 == label_2:\n",
    "                    continue\n",
    "\n",
    "                if label_stride is not None and label_2 % int(label_stride) != 0:\n",
    "                    continue\n",
    "\n",
    "                for index_2 in range(test_per_label):\n",
    "                    input_2 = test_domain[label_2][index_2]\n",
    "                    perturbation = torch.flatten(input_2 - input_1, start_dim=0).T\n",
    "                    distances_first_half = torch.matmul(\n",
    "                        unsafe_ft_first_half, perturbation\n",
    "                    )\n",
    "                    max_distance_first_half = torch.max(distances_first_half).item()\n",
    "\n",
    "                    distances_second_half = torch.matmul(\n",
    "                        unsafe_ft_second_half, perturbation\n",
    "                    )\n",
    "                    max_distance_second_half = torch.max(distances_second_half).item()\n",
    "\n",
    "                    assert not torch.isnan(distances_second_half).any()\n",
    "                    assert not torch.isnan(distances_first_half).any()\n",
    "\n",
    "                    count += 1\n",
    "                    all_threat_first_half.append(max_distance_first_half)\n",
    "                    all_threat_second_half.append(max_distance_second_half)\n",
    "                    distance_diff = abs(\n",
    "                        max_distance_first_half - max_distance_second_half\n",
    "                    )\n",
    "                    distance_sum = max_distance_first_half + max_distance_second_half\n",
    "                    distance_max = max(\n",
    "                        max_distance_first_half, max_distance_second_half\n",
    "                    )\n",
    "                    if max_diff < distance_diff:\n",
    "                        max_diff = distance_diff\n",
    "                    relative_distance_diff = distance_diff / distance_max\n",
    "                    overall_diff += relative_distance_diff\n",
    "                    all_overall_diff.append(relative_distance_diff)\n",
    "                    avg_threat += distance_sum\n",
    "\n",
    "                del unsafe_dirs_first_half, unsafe_dirs_second_half, unsafe_ft_first_half, unsafe_ft_second_half\n",
    "\n",
    "    overall_diff = overall_diff / count\n",
    "    avg_threat = avg_threat / (2 * count)\n",
    "    print(\"Comparison Experiment with \" + str(data_size) + \" data points\")\n",
    "    print(\"Average threat is \" + str(avg_threat))\n",
    "    print(\"Average threat difference is \" + str(overall_diff))\n",
    "    print(\"Max threat difference is \" + str(max_diff))\n",
    "    print(\"\\n\")\n",
    "    # Plotting a basic histogram\n",
    "    plt.figure()\n",
    "    plt.hist(all_overall_diff, bins=15, color=\"skyblue\", edgecolor=\"black\")\n",
    "    plt.axvline(overall_diff, color=\"green\", linestyle=\"dashed\", linewidth=2)\n",
    "    # Adding labels and title\n",
    "    plt.xlabel(\"Relative Threat Difference\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Histogram of Relative Threat for \" + str(data_size) + \" data points\")\n",
    "    plt.savefig(\"relative_threat_\" + str(data_size) + \".pdf\")\n",
    "    return (\n",
    "        overall_diff,\n",
    "        max_diff,\n",
    "        avg_threat,\n",
    "        all_overall_diff,\n",
    "        all_threat_first_half,\n",
    "        all_threat_second_half,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.linspace(500, 45000, 10, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size_array = torch.linspace(40000, 48000, 10, dtype=int)\n",
    "print(data_size_array)\n",
    "\n",
    "label_stride = 1\n",
    "\n",
    "active_labels = []\n",
    "for label in range(200):\n",
    "    if label % label_stride == 0:\n",
    "        active_labels.append(label)\n",
    "print(active_labels)\n",
    "print('Number of active labels - ' + str(len(active_labels)))\n",
    "\n",
    "word_active_labels = []\n",
    "for label in active_labels:\n",
    "    word_active_labels.append(label_dict[label])\n",
    "print(word_active_labels)\n",
    "\n",
    "overall_diff_array = torch.zeros(len(data_size_array))\n",
    "max_diff_array = torch.zeros(len(data_size_array))\n",
    "avg_threat_array = torch.zeros(len(data_size_array))\n",
    "all_overall_diff_array = []\n",
    "all_overall_threat_first_half = []\n",
    "all_overall_threat_second_half = []\n",
    "for index, data_size in enumerate(data_size_array):\n",
    "    (\n",
    "        overall_diff_array[index],\n",
    "        max_diff_array[index],\n",
    "        avg_threat_array[index], \n",
    "        all_overall_diff,\n",
    "        all_threat_first_half,\n",
    "        all_threat_second_half\n",
    "    ) = compare_threats(\n",
    "        int(data_size.item()), train_image_partition, test_image_partition, label_stride\n",
    "    )\n",
    "    all_overall_diff_array.append(all_overall_diff)\n",
    "    all_overall_threat_first_half.append(all_threat_first_half)\n",
    "    all_overall_threat_second_half.append(all_threat_second_half)\n",
    "\n",
    "print(overall_diff_array)\n",
    "print(max_diff_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_overall_diff_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([t for t in all_overall_diff_array[0] if t == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_overall_threat_first_half[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_overall_threat_second_half[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "same_indices = []\n",
    "for index in range(len(all_overall_threat_first_half[0])):\n",
    "    if all_overall_threat_first_half[0][index] == all_overall_threat_second_half[0][index]:\n",
    "        count += 1\n",
    "        same_indices.append(index)\n",
    "print(count)\n",
    "print(same_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([t for t in all_overall_threat_first_half[0] if t == 0]))\n",
    "print(len([t for t in all_overall_threat_second_half[0] if t == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_array = np.zeros(len(data_size_array), 100)\n",
    "percentage_thresholds = torch.logspace(-3,0,100) #torch.linspace(0,1,100)\n",
    "for index, data_size in enumerate(data_size_array):\n",
    "    all_overall_diff = all_overall_diff_array[index]\n",
    "    percentage = []\n",
    "    for threshold_index in range(100):\n",
    "        threshold = percentage_thresholds[threshold_index]\n",
    "        count = 0\n",
    "        for item in all_overall_diff:\n",
    "            if item > threshold:\n",
    "                count += 1\n",
    "        percentage.append(count/len(all_overall_diff))\n",
    "    percentage_array.append(percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "t = -1\n",
    "for item in all_overall_diff_array[0]:\n",
    "    if item > t:\n",
    "        count += 1\n",
    "count/len(all_overall_diff_array[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(human_format(800))\n",
    "print(human_format(5800))\n",
    "print(human_format(45000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for index in range(len(data_size_array)):\n",
    "    data_label = roundup(data_size_array[index]/len(active_labels), base_index=2)\n",
    "    data_label_str = human_format(data_label)\n",
    "    plt.plot(percentage_thresholds, percentage_array[index], label=data_label_str)\n",
    "\n",
    "plt.title(\n",
    "    \"Fraction of \"\n",
    "    + r\"$(x, y)$ and $(\\tilde{x}, c)$\"\n",
    "    + \" with relative threat larger than threshold\"\n",
    ")\n",
    "plt.xlabel(\"Threshold for Relative Threat\")\n",
    "plt.ylabel(\"Percentage\")\n",
    "plt.legend()\n",
    "#plt.yscale(\"log\")\n",
    "#plt.xscale(\"log\")\n",
    "plt.savefig(\"percentage_vs_threshold.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage = []\n",
    "for index in range(len(avg_threat_array)):\n",
    "    percentage.append(100*overall_diff_array[index].item()/avg_threat_array[index].item())\n",
    "print(percentage)\n",
    "\n",
    "plt.plot(dataset_sizes, percentage, label=\"Relative difference in Threat\")\n",
    "plt.xlabel('Dataset Size (maximum 1750)')\n",
    "plt.ylabel('Relative difference in Threat')\n",
    "#plt.plot(dataset_sizes, overall_diff_array.cpu().numpy(), label=\"Average Difference in Threat\")\n",
    "#plt.plot(dataset_sizes, avg_threat_array.cpu().numpy(), label=\"Average Threat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_labels = [0, 30, 60, 90, 120, 150, 180]\n",
    "word_active_labels = []\n",
    "for label in active_labels:\n",
    "    word_active_labels.append(label_dict[label])\n",
    "print(word_active_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_active_labels[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_threat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_threats(11500, train_image_partition, test_image_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_train_image_partition = get_greedy_class_subset(train_image_partition, 2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(2500//200) \n",
    "greedy_train_image_partition[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 156\n",
    "base = 0\n",
    "num = 2500//200\n",
    "col = 3\n",
    "print(label_dict[label])\n",
    "img_select = greedy_train_image_partition[label][base:base+num]\n",
    "for i in range(num):\n",
    "    img_min = img_select[i].min()\n",
    "    img_max = img_select[i].max()\n",
    "    img_select[i].clamp_(min=img_min, max=img_max)\n",
    "    img_select[i].add_(-img_min).div_(img_max - img_min + 1e-5)\n",
    "img = torchvision.utils.make_grid(img_select, ncol=col, nrow=num//col)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5,5)\n",
    "torch.max(a, dim=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "avg_train_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "minimum_train_label = torch.ones(200, device=cuda)\n",
    "minimum_train_idx = (-1, 1)\n",
    "minimum_train_score = float('inf')\n",
    "minimum_train_label_pairs = (-1, -1)\n",
    "\n",
    "min_test_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "avg_test_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "minimum_test_label = torch.ones(200, device=cuda)\n",
    "minimum_test_idx = (-1, 1)\n",
    "minimum_test_score = float('inf')\n",
    "minimum_test_label_pairs = (-1, -1)\n",
    "\n",
    "for label in range(200):\n",
    "    train_images_ft = torch.flatten(train_image_partition[label], start_dim=1)\n",
    "    test_images_ft = torch.flatten(test_image_partition[label], start_dim=1)\n",
    "    \n",
    "    for diff_label in range(200):\n",
    "        if label == diff_label:\n",
    "            min_train_scores_all_class[label, label] = 1.0\n",
    "            continue \n",
    "\n",
    "        if min_train_scores_all_class[diff_label, label] < float('inf'):\n",
    "            min_train_scores_all_class[label, diff_label] = min_train_scores_all_class[diff_label, label]\n",
    "        \n",
    "        diff_train_images_ft = torch.flatten(greedy_train_image_partition[diff_label], start_dim=1)        \n",
    "        train_pairwise_scores = pairwise_cosine_similarity(train_images_ft, diff_train_images_ft)\n",
    "        train_max_pairwise_score_values = torch.max(train_pairwise_scores, dim=1).values\n",
    "        train_max_pairwise_score_idx = torch.max(train_pairwise_scores, dim=1).indices\n",
    "        min_train_scores_all_class[label, diff_label] = torch.min(train_max_pairwise_score_values).item()\n",
    "        avg_train_scores_all_class[label, diff_label] = torch.mean(train_max_pairwise_score_values).item()\n",
    "\n",
    "        if min_train_scores_all_class[label, diff_label] < minimum_train_score:\n",
    "            minimum_train_score = min_train_scores_all_class[label, diff_label] \n",
    "            minimum_train_label_pairs = (label, diff_label)\n",
    "            train_id1 = torch.argmin(train_max_pairwise_score_values).item()\n",
    "            train_id2 = train_max_pairwise_score_idx[train_id1].item()\n",
    "            minimum_train_idx = (train_id1, train_id2)\n",
    "\n",
    "        test_pairwise_scores = pairwise_cosine_similarity(test_images_ft, diff_train_images_ft)\n",
    "        test_max_pairwise_score_values = torch.max(test_pairwise_scores, dim=1).values\n",
    "        test_max_pairwise_score_idx = torch.max(test_pairwise_scores, dim=1).indices\n",
    "        min_test_scores_all_class[label, diff_label] = torch.min(test_max_pairwise_score_values).item()\n",
    "        avg_test_scores_all_class[label, diff_label] = torch.mean(test_max_pairwise_score_values).item()\n",
    "        \n",
    "        if min_test_scores_all_class[label, diff_label] < minimum_test_score:\n",
    "            minimum_test_score = min_test_scores_all_class[label, diff_label] \n",
    "            minimum_test_label_pairs = (label, diff_label)\n",
    "            test_id1 = torch.argmin(test_max_pairwise_score_values).item()\n",
    "            test_id2 = test_max_pairwise_score_idx[test_id1].item()\n",
    "            minimum_test_idx = (test_id1, test_id2)\n",
    "            \n",
    "print('minimum train score is ' + str(minimum_train_score))\n",
    "print('minimum training score is achieved by label pair - ' + str(minimum_train_label_pairs))\n",
    "print('minimum training score is achieved by input idx - ' + str(minimum_train_idx))\n",
    "print('\\n')\n",
    "print('minimum test score is ' + str(minimum_test_score))\n",
    "print('minimum test score is achieved by label pair - ' + str(minimum_test_label_pairs))\n",
    "print('minimum test score is achieved by input idx - ' + str(minimum_test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_dict[140])\n",
    "print(label_dict[156])\n",
    "print(label_dict[72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_test_scores_all_class[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_test_scores_all_class[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_train_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "minimum_train_label = torch.ones(200, device=cuda)\n",
    "minimum_train_idx = (-1, 1)\n",
    "minimum_train_score = float('inf')\n",
    "minimum_train_labels = (-1, -1)\n",
    "\n",
    "min_test_scores_all_class = torch.ones(200,200, device=cuda)*float('inf')\n",
    "minimum_test_label = torch.ones(200, device=cuda)\n",
    "minimum_test_idx = (-1, 1)\n",
    "minimum_test_score = float('inf')\n",
    "minimum_test_labels = (-1, -1)\n",
    "\n",
    "for label in range(200):\n",
    "    train_images_ft = torch.flatten(train_image_partition[label], start_dim=1)\n",
    "    test_images_ft = torch.flatten(test_image_partition[label], start_dim=1)\n",
    "    for diff_label in range(200):\n",
    "        greedy_train_images_ft = torch.flatten(greedy_train_image_partition[diff_label], start_dim=1)\n",
    "        train_pairwise_scores = pairwise_cosine_similarity(train_images_ft, greedy_train_images_ft)\n",
    "        train_max_pairwise_score_values = torch.max(train_pairwise_scores, dim=1).values\n",
    "        train_max_pairwise_score_idx = torch.max(train_pairwise_scores, dim=1).indices\n",
    "        min_train_scores_all_class[label, diff_label] = torch.min(train_max_pairwise_score_values).item()\n",
    "        \n",
    "        if min_train_scores_all_class[label, diff_label] < minimum_train_score:\n",
    "            minimum_train_score = min_train_scores_all_class[label, diff_label] \n",
    "            minimum_train_labels = (label, diff_label)\n",
    "            train_id1 = torch.argmin(train_max_pairwise_score_values).item()\n",
    "            train_id2 = train_max_pairwise_score_idx[train_id1].item()\n",
    "            minimum_train_idx = (train_id1, train_id2)\n",
    "\n",
    "        test_pairwise_scores = pairwise_cosine_similarity(test_images_ft, greedy_train_images_ft)\n",
    "        test_max_pairwise_score_values = torch.max(test_pairwise_scores, dim=1).values\n",
    "        test_max_pairwise_score_idx = torch.max(test_pairwise_scores, dim=1).indices\n",
    "        min_test_scores_all_class[label, diff_label] = torch.min(test_max_pairwise_score_values).item()\n",
    "        \n",
    "        if min_test_scores_all_class[label, diff_label] < minimum_test_score:\n",
    "            minimum_test_score = min_test_scores_all_class[label, diff_label] \n",
    "            minimum_test_labels = (label, diff_label)\n",
    "            test_id1 = torch.argmin(test_max_pairwise_score_values).item()\n",
    "            test_id2 = test_max_pairwise_score_idx[test_id1].item()\n",
    "            minimum_test_idx = (test_id1, test_id2)\n",
    "            \n",
    "print('minimum train score is ' + str(minimum_train_score))\n",
    "print('minimum training score is achieved by label pair - ' + str(minimum_train_labels))\n",
    "print('minimum training score is achieved by input idx - ' + str(minimum_train_idx))\n",
    "print('\\n')\n",
    "print('minimum test score is ' + str(minimum_test_score))\n",
    "print('minimum test score is achieved by label pair - ' + str(minimum_test_labels))\n",
    "print('minimum test score is achieved by input idx - ' + str(minimum_test_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(unsafe_dirs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reference_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.flatten(unsafe_dirs, start_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "perturbation = train_image_partition[alt_label] - reference_input\n",
    "perturbation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(torch.mm(torch.flatten(unsafe_dirs, start_dim=1), torch.flatten(perturbation, start_dim=1).T), dim=0).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alt_input = torch.randn(3, 64, 64, device=cuda)*0.5 + reference_input \n",
    "reference_input_index = 150\n",
    "reference_label = 42\n",
    "alt_label = 49\n",
    "alt_input_index = 20\n",
    "\n",
    "reference_input = train_image_partition[reference_label][reference_input_index]\n",
    "unsafe_dirs, unsafe_normalization = compute_unsafe_dir(reference_input, reference_label, greedy_train_image_partition, beta=1.0)\n",
    "\n",
    "alt_input = train_image_partition[alt_label][alt_input_index]\n",
    "current_perturbation = alt_input - reference_input \n",
    "unsafe_ft = torch.flatten(unsafe_dirs, start_dim=1)\n",
    "num_rounds = 10000\n",
    "epsilon = 0.000001\n",
    "listp = [] \n",
    "listdist = []\n",
    "\n",
    "for t in range(num_rounds):\n",
    "    distances = torch.matmul(unsafe_ft, torch.flatten(current_perturbation, start_dim=0).T)\n",
    "    max_distance = torch.max(distances).item()\n",
    "    if t % 5000 == 0: \n",
    "        print(max_distance)\n",
    "        listp.append(current_perturbation+reference_input)\n",
    "        listdist.append(max_distance)\n",
    "    \n",
    "    if max_distance <= epsilon:\n",
    "        print(\"stopping\")\n",
    "        break\n",
    "    else:\n",
    "        unsafe_index = torch.argmax(distances).item()\n",
    "        u_dir = unsafe_dirs[int(unsafe_index)]\n",
    "        current_perturbation = current_perturbation - (distances[unsafe_index]-epsilon)*u_dir*unsafe_normalization[i]\n",
    "    \n",
    "listp.append(current_perturbation+reference_input)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(listp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = len(listp)\n",
    "list_t_0 = torch.zeros(num_p, 3, 64, 64, device=cuda)\n",
    "list_t_0[0] = reference_input\n",
    "z_norms_0 = []\n",
    "max_d_0 = [] \n",
    "\n",
    "for i in range(1,num_p):\n",
    "    list_t_0[i] = listp[num_p-1-i]\n",
    "    \n",
    "for i in range(num_p):\n",
    "    pert = list_t_0[i] - reference_input\n",
    "    z_norms_0.append(torch.linalg.norm(torch.flatten(pert, start_dim=0),ord=2).item())\n",
    "    distances = torch.matmul(unsafe_ft, torch.flatten(pert, start_dim=0).T)\n",
    "    max_d_0.append(torch.max(distances).item())\n",
    "\n",
    "for i in range(num_p):\n",
    "    img_min = list_t_0[i].min()\n",
    "    img_max = list_t_0[i].max()\n",
    "    list_t_0[i].clamp_(min=img_min, max=img_max)\n",
    "    list_t_0[i].add_(-img_min).div_(img_max - img_min + 1e-10)\n",
    "img = torchvision.utils.make_grid(list_t_0, nrow=10, ncol=5)\n",
    "print(listdist.reverse())\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "print(label_dict[reference_label])\n",
    "print(label_dict[alt_label])\n",
    "print(z_norms_0)\n",
    "print(max_d_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = len(listp)\n",
    "list_t_1 = torch.zeros(num_p, 3, 64, 64, device=cuda)\n",
    "list_t_1[0] = reference_input\n",
    "z_norms_1 = []\n",
    "max_d_1 = []\n",
    "\n",
    "for i in range(1,num_p):\n",
    "    list_t_1[i] = reference_input + i/num_p*(alt_input - reference_input) \n",
    "\n",
    "for i in range(num_p):\n",
    "    pert = list_t_1[i] - reference_input\n",
    "    z_norms_1.append(torch.linalg.norm(torch.flatten(pert, start_dim=0),ord=2).item())\n",
    "    distances = torch.matmul(unsafe_ft, torch.flatten(pert, start_dim=0).T)\n",
    "    max_d_1.append(torch.max(distances).item())\n",
    "\n",
    "for i in range(num_p):\n",
    "    img_min = list_t_1[i].min()\n",
    "    img_max = list_t_1[i].max()\n",
    "    list_t_1[i].clamp_(min=img_min, max=img_max)\n",
    "    list_t_1[i].add_(-img_min).div_(img_max - img_min + 1e-10)\n",
    "img = torchvision.utils.make_grid(list_t_1, nrow=10, ncol=5)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "print(label_dict[reference_label])\n",
    "print(label_dict[alt_label])\n",
    "print(z_norms_1)\n",
    "print(max_d_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linalg.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = len(listp)\n",
    "list_t_2 = torch.zeros(num_p, 3, 64, 64, device=cuda)\n",
    "z = torch.zeros_like(reference_input)\n",
    "z_norms_2 = []\n",
    "max_d_2 = []\n",
    "\n",
    "x_start = 0 \n",
    "x_end = 30\n",
    "y_start = 30\n",
    "y_end = 64\n",
    "\n",
    "list_t_2[0] = reference_input\n",
    "for i in range(1,num_p):\n",
    "    list_t_2[i] = reference_input \n",
    "    list_t_2[i][:, x_start:int((2*i)/num_p*x_end), y_start:int((2*i)/num_p*y_end)] = 0.3 \n",
    "\n",
    "for i in range(num_p):\n",
    "    pert = list_t_2[i] - reference_input\n",
    "    z_norms_2.append(torch.linalg.norm(torch.flatten(pert, start_dim=0),ord=2).item())\n",
    "    distances = torch.matmul(unsafe_ft, torch.flatten(pert, start_dim=0).T)\n",
    "    max_d_2.append(torch.max(distances).item())\n",
    "\n",
    "for i in range(num_p):\n",
    "    img_min = list_t_2[i].min()\n",
    "    img_max = list_t_2[i].max()\n",
    "    list_t_2[i].clamp_(min=img_min, max=img_max)\n",
    "    list_t_2[i].add_(-img_min).div_(img_max - img_min + 1e-10)\n",
    "img = torchvision.utils.make_grid(list_t_2, nrow=10, ncol=5)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "print(label_dict[reference_label])\n",
    "print(label_dict[alt_label])\n",
    "print(z_norms_2)\n",
    "print(max_d_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_a = []\n",
    "list_a.extend(list_t_0)\n",
    "list_a.extend(list_t_1)\n",
    "list_a.extend(list_t_2)\n",
    "num = len(list_a)\n",
    "z_norms = z_norms_0 + z_norms_1 + z_norms_2\n",
    "max_d = max_d_0 + max_d_1 + max_d_2 \n",
    "indices = [0, 1, 4, 8]\n",
    "list_new = []\n",
    "list_new.append(list_a[0])\n",
    "list_new.append(list_a[1])\n",
    "list_new.append(list_a[4])\n",
    "list_new.append(list_a[8])\n",
    "list_a = list_new \n",
    "print(len(list_a))\n",
    "\n",
    "for i in range(len(list_a)):\n",
    "    img_min = list_a[i].min()\n",
    "    img_max = list_a[i].max()\n",
    "    list_a[i].clamp_(min=img_min, max=img_max)\n",
    "    list_a[i].add_(-img_min).div_(img_max - img_min + 1e-10)\n",
    "img = torchvision.utils.make_grid(list_a, nrow=10, ncol=5)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "print(label_dict[reference_label])\n",
    "print(label_dict[alt_label])\n",
    "print(z_norms)\n",
    "print(max_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(max_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_p = len(listp)\n",
    "list_t = torch.zeros(num_p, 3, 64, 64, device=cuda)\n",
    "z = torch.zeros_like(reference_input)\n",
    "z_norms = []\n",
    "max_d = []\n",
    "\n",
    "x_start = 45 \n",
    "x_end = 60\n",
    "y_start = 0\n",
    "y_end = 24\n",
    "\n",
    "x_start_2 = 0\n",
    "x_end_2 = 20\n",
    "y_start_2 = 40\n",
    "y_end_2 = 64\n",
    "\n",
    "list_t[0] = reference_input\n",
    "for i in range(1,num_p):\n",
    "    list_t[i] = reference_input \n",
    "    list_t[i][:, x_start:int((2*i)/num_p*x_end), y_start:int((2*i)/num_p*y_end)] = 0.3 \n",
    "    list_t[i][:, x_start_2:int((2*i)/num_p*x_end_2), y_start_2:int((2*i)/num_p*y_end_2)] = 0.3 \n",
    "\n",
    "for i in range(num_p):\n",
    "    pert = list_t[i] - reference_input\n",
    "    z_norms.append(torch.linalg.norm(torch.flatten(pert, start_dim=0),ord=2).item())\n",
    "    distances = torch.matmul(unsafe_ft, torch.flatten(pert, start_dim=0).T)\n",
    "    max_d.append(torch.max(distances).item())\n",
    "\n",
    "for i in range(num_p):\n",
    "    img_min = list_t[i].min()\n",
    "    img_max = list_t[i].max()\n",
    "    list_t[i].clamp_(min=img_min, max=img_max)\n",
    "    list_t[i].add_(-img_min).div_(img_max - img_min + 1e-10)\n",
    "img = torchvision.utils.make_grid(list_t, nrow=10, ncol=5)\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.imshow(img.cpu().permute(1, 2, 0))\n",
    "print(label_dict[reference_label])\n",
    "print(label_dict[alt_label])\n",
    "print(z_norms)\n",
    "print(max_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_perturbation = perturbation \n",
    "    for t in range(len(num_rounds)):\n",
    "        for (u, M) in zip(unsafe_dir, unsafe_normalization):\n",
    "            if dist_type == 'PL' or dist_type == 'PD':\n",
    "                distance = torch.sum(torch.mul(u, current_perturbation))/M \n",
    "                current_perturbation = current_perturbation - (distance-epsilon)*u\n",
    "                if dist_type == 'PD':\n",
    "                    distance = torch.sum(torch.mul(-u, current_perturbation))/M\n",
    "                    current_perturbation = current_perturbation - (distance-epsilon)*(-u)\n",
    "            else:\n",
    "                continue \n",
    "        \n",
    "        distance = non_isotropic_dist(unsafe_dir, unsafe_normalization, current_perturbation, dist_type=dist_type, return_device=device, return_type=None)\n",
    "        if distance <= epsilon:\n",
    "            break \n",
    "    \n",
    "    distance = non_isotropic_dist(unsafe_dir, unsafe_normalization, current_perturbation, dist_type=dist_type, return_device=device, return_type=None)\n",
    "    \n",
    "    if distance > epsilon:\n",
    "        scale_flag = True\n",
    "        current_perturbation *= (epsilon/distance)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distance = float('inf')\n",
    "per_label = len(greedy_train_image_partition[label])\n",
    "#train_distances = torch.zeros(200, 200, per_label, per_label, device=cuda)\n",
    "for label in range(200):\n",
    "    for input_index in range(per_label):\n",
    "        if label % 25 == 0 and input_index % 10 == 0:\n",
    "            print(\"Finding minimum at label - \" + str(label) + ' and input ' + str(input_index))\n",
    "        reference_input = greedy_train_image_partition[label][input_index]\n",
    "        unsafe_dirs = compute_unsafe_dir(reference_input, label, greedy_train_image_partition, beta=1.0)\n",
    "        \n",
    "        unsafe_ft = torch.flatten(unsafe_dirs, start_dim=1)\n",
    "        for diff_label in range(200):\n",
    "            if label == diff_label: continue \n",
    "            perturbation = greedy_train_image_partition[diff_label] - reference_input\n",
    "            unsafe_x_perturbation = torch.mm(unsafe_ft, torch.flatten(perturbation, start_dim=1).T)\n",
    "            distance_per_perturbation = torch.max(unsafe_x_perturbation, dim=0).values\n",
    "            distance = torch.min(distance_per_perturbation)\n",
    "            \n",
    "            if distance < 0.0:\n",
    "                print('label is ' + str(label))\n",
    "                print('diff label is ' + str(diff_label))\n",
    "                print('distance is ' + str(distance))\n",
    "                break\n",
    "                \n",
    "            if distance < min_distance:\n",
    "                min_distance = distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "200*500*200*500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_unsafe_dir(reference_input, reference_label, selected_domain, selected_labels, classifier = None, beta=0.7):\n",
    "    assert len(selected_domain) == len(selected_labels)\n",
    "    \n",
    "    unsafe_dirs = torch.zeros_like(selected_domain)\n",
    "    unsafe_normalization = torch.ones(len(selected_domain), device=cuda)*float('inf')\n",
    "    \n",
    "    for (index, input) in enumerate(selected_domain):\n",
    "        norm_diff = torch.linalg.norm(input - reference_input, ord=2)\n",
    "        unsafe_dirs[index] = (input-reference_input)/norm_diff\n",
    "            \n",
    "        if selected_labels[index] != reference_label:\n",
    "            if classifier is not None: \n",
    "                # binary search to compute normalization when the true labeling function is given\n",
    "                low = 0\n",
    "                high = 1\n",
    "                while high - low > 1e-5:\n",
    "                    alpha = (high + low)/2\n",
    "                    input_alpha = reference_input + alpha*(input-reference_input)\n",
    "                    label_alpha = predict_label(classifier, input_alpha)\n",
    "                    if label_alpha == reference_label:\n",
    "                        low = alpha\n",
    "                    else:\n",
    "                        high = alpha\n",
    "                alpha = low\n",
    "                input_alpha = reference_input + alpha*(input-reference_input)\n",
    "                unsafe_normalization[index] = torch.linalg.norm(input_alpha-reference_input, ord=2)\n",
    "            else:\n",
    "                unsafe_normalization[index] = norm_diff*beta \n",
    "    \n",
    "    return unsafe_dirs, unsafe_normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_isotropic_dist(unsafe_dir, unsafe_normalization, perturbation, dist_type='PL', return_device='cpu', return_type=None):\n",
    "    if dist_type not in ['PL', 'PD', 'WD']:\n",
    "        raise ValueError('Non-isotropic distance type should be one of PL, PD, WD')\n",
    "    \n",
    "    distance = float('inf')\n",
    "    \n",
    "    element_wise_mul = torch.mul(unsafe_dir, perturbation)\n",
    "    \n",
    "    if dist_type == 'PL' or dist_type == 'PD':\n",
    "        scaled_projections = torch.div(torch.sum(element_wise_mul, dim=1), unsafe_normalization)\n",
    "        if dist_type == 'PL':\n",
    "            distance = torch.max(scaled_projections)\n",
    "        elif dist_type == 'PD':\n",
    "            distance = torch.max(torch.abs(scaled_projections))\n",
    "    \n",
    "    if dist_type == 'WD':\n",
    "        unsafe_4_norm = torch.linalg.norm(unsafe_dir, dim=1, ord=4)**2 # 4-norm\n",
    "        modified_normalization = torch.mul(unsafe_normalization, unsafe_4_norm)\n",
    "        scaled_distances = torch.div(torch.linalg.norm(element_wise_mul, dim=1, ord=2), modified_normalization)\n",
    "        distance = torch.max(scaled_distances)\n",
    "    \n",
    "    distance = distance.detach().to(device=return_device)\n",
    "    \n",
    "    if return_type is not None:\n",
    "        return distance.numpy()\n",
    "    else:\n",
    "        return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_isotropic_projection(unsafe_dir, unsafe_normalization, perturbation, epsilon=1.0, dist_type='PL', num_rounds=3):\n",
    "    if dist_type not in ['PL', 'PD', 'WD']:\n",
    "        raise ValueError('Non-isotropic distance type should be one of PL, PD, WD')\n",
    "    \n",
    "    if dist_type == 'WD':\n",
    "        raise ValueError('Projection onto WD currently unsupported')\n",
    "    \n",
    "    device = perturbation.get_device()\n",
    "    scale_flag = False \n",
    "    current_perturbation = perturbation \n",
    "    \n",
    "    for t in range(len(num_rounds)):\n",
    "        for (u, M) in zip(unsafe_dir, unsafe_normalization):\n",
    "            if dist_type == 'PL' or dist_type == 'PD':\n",
    "                distance = torch.sum(torch.mul(u, current_perturbation))/M \n",
    "                current_perturbation = current_perturbation - (distance-epsilon)*u\n",
    "                if dist_type == 'PD':\n",
    "                    distance = torch.sum(torch.mul(-u, current_perturbation))/M\n",
    "                    current_perturbation = current_perturbation - (distance-epsilon)*(-u)\n",
    "            else:\n",
    "                continue \n",
    "        \n",
    "        distance = non_isotropic_dist(unsafe_dir, unsafe_normalization, current_perturbation, dist_type=dist_type, return_device=device, return_type=None)\n",
    "        if distance <= epsilon:\n",
    "            break \n",
    "    \n",
    "    distance = non_isotropic_dist(unsafe_dir, unsafe_normalization, current_perturbation, dist_type=dist_type, return_device=device, return_type=None)\n",
    "    \n",
    "    if distance > epsilon:\n",
    "        scale_flag = True\n",
    "        current_perturbation *= (epsilon/distance)\n",
    "    \n",
    "    return current_perturbation, scale_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_types = ['l2', 'l1', 'linf', 'PL', 'PD', 'WD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latexify_dist(dist_type: str):\n",
    "    if dist_type == 'l2': return r'$\\ell_2$'\n",
    "    elif dist_type == 'linf': return r'$\\ell_{\\infty}$'\n",
    "    elif dist_type == 'l1': return r'$\\ell_1$'\n",
    "    else: return dist_type\n",
    "\n",
    "def latexify_inp(index: int):\n",
    "    if index == 0: return r'$x$'\n",
    "    elif index == 1: return r'$x_1$'\n",
    "    elif index == 2: return r'$x_2$'\n",
    "    elif index == 3: return r'$\\tilde{x}$'\n",
    "    \n",
    "def latexify_h(index):\n",
    "    if index is None: return r'$h^{\\star}$'\n",
    "    elif index == 1: return r'$h_1$'\n",
    "    elif index == 2: return r'$h_2$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(reference_input, reference_label, domain, true_labels, selected_domain = None, selected_labels = None, classifier = None, dist_type='l2'):\n",
    "    print(\"Computing \" + dist_type + \" distances\")\n",
    "    if dist_type not in distance_types:\n",
    "        raise ValueError('Distance type should be one of l2, l1, linf, PL, PD, WD')\n",
    "    \n",
    "    if selected_domain is not None and selected_labels is not None:\n",
    "        assert len(selected_domain) == len(selected_labels)\n",
    "        unsafe_dir, unsafe_normalization = compute_unsafe_dir(reference_input, reference_label, selected_domain, selected_labels, classifier=classifier)\n",
    "    else:\n",
    "        unsafe_dir, unsafe_normalization = compute_unsafe_dir(reference_input, reference_label, domain, true_labels, classifier=classifier)        \n",
    "    \n",
    "    distances = []\n",
    "    for (index, input) in enumerate(domain):\n",
    "        if index % 100 == 0:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Computing distances at index: \" + str(index) +  \", out of \" + str(len(domain) - 1) + \" points.\")\n",
    "        perturbation = input - reference_input\n",
    "        if dist_type == 'l2':\n",
    "            distance = torch.linalg.norm(perturbation, ord=2).detach().cpu().numpy()\n",
    "        elif dist_type == 'l1':\n",
    "            distance = torch.linalg.norm(perturbation, ord=1).detach().cpu().numpy()\n",
    "        elif dist_type == 'linf':\n",
    "            distance = torch.linalg.norm(perturbation, ord=float('inf')).detach().cpu().numpy()\n",
    "        elif dist_type in ['PL', 'PD', 'WD']:\n",
    "            distance = non_isotropic_dist(unsafe_dir, unsafe_normalization, perturbation, dist_type)\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def sublevel_set(selected_domain, distances, threshold):\n",
    "    sublevel = []\n",
    "    for input, distance in zip(selected_domain, distances):\n",
    "        if distance <= threshold:\n",
    "            sublevel.append(input.detach().cpu().numpy())\n",
    "    return sublevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_keys = subset_domain_class.keys()\n",
    "print(len(l_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_keys_list = list(l_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_keys_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_domain_class[l_keys_list[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distances(reference_domain, reference_labels, domain, true_labels, classifier=h_star, distance_types=distance_types, greedy_subset=False, num_points=100):\n",
    "    selected_domain = None \n",
    "    selected_labels = None \n",
    "    \n",
    "    if greedy_subset:\n",
    "        num_labels = len(torch.unique(true_labels))\n",
    "        subset_domain_class = get_greedy_class_subset(domain, true_labels, num_labels, num_points)\n",
    "        inp_shape = list(domain.shape)[1:]\n",
    "        selected_domain_shape = [num_points] + inp_shape\n",
    "        selected_domain = torch.zeros(selected_domain_shape, device=cuda)\n",
    "        selected_labels = torch.ones(num_points, device=cuda)\n",
    "        label_keys = list(subset_domain_class.keys())\n",
    "        increment = num_points//num_labels\n",
    "        for label_index in range(len(label_keys)):\n",
    "            selected_domain[label_index*increment:(label_index+1)*increment] = subset_domain_class[label_keys[label_index]]\n",
    "            selected_labels[label_index*increment:(label_index+1)*increment] *= label_keys[label_index]\n",
    "\n",
    "    distances = dict()\n",
    "    for dist_type in distance_types:\n",
    "        if greedy_subset and dist_type not in ['PL', 'PD', 'WD']:\n",
    "            continue \n",
    "                \n",
    "        for index in range(len(reference_domain)):\n",
    "            key = \"x\" + str(index) + \"_\" + dist_type\n",
    "            if greedy_subset:\n",
    "                key += \"_greedy_\" + str(num_points)\n",
    "            \n",
    "            distances[key] = get_distances(reference_domain[index], reference_labels[index], domain, true_labels, selected_domain=selected_domain, selected_labels=selected_labels, classifier=classifier, dist_type=dist_type)\n",
    "    \n",
    "    return distances, selected_domain, selected_labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_distances, selected_domain, selected_labels = generate_distances(reference_domain, reference_labels, domain, true_labels, greedy_subset=True, num_points=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_distances.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distance_intensity(corners, reference_points, distances, domain, selected_domain=None, distance_types=distance_types, greedy_subset=False, num_points=100):\n",
    "    x0, x1, x2, xtil = reference_points[0], reference_points[1], reference_points[2], reference_points[3]\n",
    "    x_left, y_left, x_right, y_right, x_down, y_down, x_up, y_up = generate_data_domain(corners)\n",
    "    x, y_star, y_1, y_2 = generate_decision_boundary(corners)\n",
    "    \n",
    "    domain_np = domain.cpu().numpy()\n",
    "    domain_x = [d[0] for d in domain_np]\n",
    "    domain_y = [d[1] for d in domain_np]\n",
    "    \n",
    "    for dist_type in distance_types:\n",
    "        if greedy_subset and dist_type not in ['PL', 'PD', 'WD']:\n",
    "            continue \n",
    "        \n",
    "        for index in range(len(reference_points)):\n",
    "            key = \"x\" + str(index) + \"_\" + dist_type\n",
    "            if greedy_subset:\n",
    "                key += \"_greedy_\" + str(num_points)\n",
    "            \n",
    "            distance_domain = distances[key]\n",
    "            plt.figure()\n",
    "            title_str = latexify_dist(dist_type) + \" threat \"\n",
    "            title_str += \" from reference point \" + latexify_inp(index)\n",
    "            plt.title(title_str)\n",
    "            \n",
    "            # plot the data domain\n",
    "            plt.plot(x_left, y_left, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_right, y_right, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_down, y_down, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_up, y_up, color=\"black\", linewidth=3)\n",
    "    \n",
    "            # plot true labeling decision boundary \n",
    "            plt.plot(x, y_star, label=r'$h^{\\star}$', linewidth=3)\n",
    "        \n",
    "            # plot reference points\n",
    "            plt.plot(x0[0], x0[1], color=\"black\", marker=latexify_inp(0), markersize=9)\n",
    "            plt.plot(x1[0], x1[1], color=\"black\", marker=latexify_inp(1), markersize=12)\n",
    "            plt.plot(x2[0], x2[1], color=\"black\", marker=latexify_inp(2), markersize=12)\n",
    "            plt.plot(xtil[0], xtil[1], color='black', marker=latexify_inp(3), markersize=12)\n",
    "            \n",
    "            # Plot the distance intensity map\n",
    "            plt.scatter(domain_x, domain_y, c=distance_domain, s=2, cmap=\"plasma\")\n",
    "            plt.colorbar(orientation='horizontal')\n",
    "            \n",
    "            if selected_domain is not None:\n",
    "                selected_np = selected_domain.cpu().numpy()\n",
    "                selected_x = [d[0] for d in selected_np]\n",
    "                selected_y = [d[1] for d in selected_np]\n",
    "                plt.scatter(selected_x, selected_y, color=\"black\", s=5)\n",
    "    \n",
    "            \n",
    "            plt.axis('off')\n",
    "            plt.savefig(\"./distance_intensity_\" + key + \".pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distance_intensity(corners, reference_points, greedy_distances, domain, selected_domain=selected_domain, greedy_subset=True, num_points=20)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute certified threshold for a given point based on its distances matrix and the collection of all points. \n",
    "def compute_certified_threshold(reference_domain, reference_labels, domain, true_labels, distances):\n",
    "    certified_thresholds = dict()\n",
    "    for dist_type in distance_types:\n",
    "        for r_index in range(len(reference_domain)):\n",
    "            key = \"x\" + str(r_index) + \"_\" + dist_type\n",
    "            reference_label = reference_labels[r_index]\n",
    "            threshold = float('inf')\n",
    "            for index in range(len(domain)):\n",
    "                if true_labels[index] != reference_label and threshold > distances[key][index]:\n",
    "                    threshold = distances[key][index]\n",
    "            certified_thresholds[key] = threshold\n",
    "    return certified_thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_labels_h1 = predict_label(h_1, reference_domain)\n",
    "reference_labels_h2 = predict_label(h_2, reference_domain)\n",
    "\n",
    "domain_labels_h1 = predict_label(h_1, domain)\n",
    "domain_labels_h2 = predict_label(h_2, domain)\n",
    "\n",
    "certified_thresholds_hstar = compute_certified_threshold(reference_domain, reference_labels, domain, true_labels, distances)\n",
    "certified_thresholds_h1 = compute_certified_threshold(reference_domain, reference_labels_h1, domain, domain_labels_h1, distances)\n",
    "certified_thresholds_h2 = compute_certified_threshold(reference_domain, reference_labels_h2, domain, domain_labels_h2, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(certified_thresholds_hstar['x0_PL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latexify_h(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latexify_dist('l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latexify_inp(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sublevel_sets(corners, reference_points, distances, domain, certified_thresholds, distance_types=distance_types, h_index=None):\n",
    "    x0, x1, x2, xtil = reference_points[0], reference_points[1], reference_points[2], reference_points[3]\n",
    "    x_left, y_left, x_right, y_right, x_down, y_down, x_up, y_up = generate_data_domain(corners)\n",
    "    x, y_star, y_1, y_2 = generate_decision_boundary(corners)\n",
    "    h_str = \"h\" + str(h_index) if h_index is not None else \"hstar\"\n",
    "            \n",
    "    domain_np = domain.cpu().numpy()\n",
    "    domain_x = [d[0] for d in domain_np]\n",
    "    domain_y = [d[1] for d in domain_np]\n",
    "    \n",
    "    for dist_type in distance_types:\n",
    "        for index in range(len(reference_points)):\n",
    "            key = \"x\" + str(index) + \"_\" + dist_type\n",
    "            distance_domain = distances[key]\n",
    "            certified_threshold = certified_thresholds[key]\n",
    "            cert_str = \"%.2f\" % certified_threshold \n",
    "            title_str = latexify_dist(dist_type) + \" certified threshold for \" + latexify_h(h_index) + \" at \" + latexify_inp(index) + \" is \" + cert_str\n",
    "            plt.figure()\n",
    "            plt.title(title_str)\n",
    "            \n",
    "            # plot the data domain\n",
    "            plt.plot(x_left, y_left, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_right, y_right, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_down, y_down, color=\"black\", linewidth=3)\n",
    "            plt.plot(x_up, y_up, color=\"black\", linewidth=3)\n",
    "    \n",
    "            # plot true labeling decision boundary \n",
    "            plt.plot(x, y_star, label=r'$h^{\\star}$', linewidth=3)\n",
    "            \n",
    "            if h_index == 1:\n",
    "                plt.plot(x, y_1, color='magenta', label=latexify(h_index), linestyle=\"dashed\")\n",
    "                plt.fill_between(x, y1=y_1, y2=y_star, color= \"magenta\", alpha= 0.05, hatch='///')\n",
    "            elif h_index == 2:\n",
    "                plt.plot(x, y_2, color='purple', label=latexify(h_index), linestyle=\"dashed\")\n",
    "                plt.fill_between(x, y1=y_2, y2=y_star, color= \"purple\", alpha= 0.05, hatch='///')\n",
    "    \n",
    "            # plot reference points\n",
    "            plt.plot(x0[0], x0[1], color=\"black\", marker=r\"$x$\", markersize=9)\n",
    "            plt.plot(x1[0], x1[1], color=\"black\", marker=r\"$x_1$\", markersize=12)\n",
    "            plt.plot(x2[0], x2[1], color=\"black\", marker=r\"$x_2$\", markersize=12)\n",
    "            plt.plot(xtil[0], xtil[1], color='black', marker=r'$\\tilde{x}$', markersize=12)\n",
    "            \n",
    "            # Plot the sublevel sets upto certified threshold\n",
    "            epsilons = np.linspace(0, certified_threshold, 5)\n",
    "            for eps in epsilons: \n",
    "                sublevel = sublevel_set(domain, distance_domain, eps)\n",
    "                sublevel_x = [d[0] for d in sublevel]\n",
    "                sublevel_y = [d[1] for d in sublevel]\n",
    "                plt.scatter(sublevel_x, sublevel_y, c='red', s=0.1/(0.1+eps))\n",
    "\n",
    "            plt.axis('off')\n",
    "            plt.savefig(\"./certified threshold_\" + h_str + key + \".pdf\", bbox_inches='tight')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sublevel_sets(corners, reference_points, distances, domain, certified_thresholds_hstar, h_index=None)\n",
    "\n",
    "plot_sublevel_sets(corners, reference_points, distances, domain, certified_thresholds_h1, h_index=1)\n",
    "\n",
    "plot_sublevel_sets(corners, reference_points, distances, domain, certified_thresholds_h2, h_index=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unsafe_dir, unsafe_normalization = compute_unsafe_dir(p_ref, domain)\n",
    "# unsafe_pert = []\n",
    "# for d in unsafe_dir:\n",
    "#     unsafe_pert.append(sum(p_ref, d))\n",
    "\n",
    "# unsafe_pert_x = [d.x for d in unsafe_pert]\n",
    "# unsafe_pert_y = [d.y for d in unsafe_pert]\n",
    "\n",
    "\n",
    "# sublevel_PL = sublevel_set(domain, distance_domain_PL, 0.0)\n",
    "\n",
    "# sublevel_PL_x = [d.x for d in sublevel_PL]\n",
    "# sublevel_PL_y = [d.y for d in sublevel_PL]\n",
    "\n",
    "\n",
    "# plt.scatter(sublevel_PL_x, sublevel_PL_y, c='green', s=0.1)\n",
    "# plt.scatter(unsafe_pert_x, unsafe_pert_y, c='red', s=0.1)\n",
    "# #plt.plot([3.8],[0.9], color='black', marker=r'$x$', markersize=9)\n",
    "# #plt.plot([2.7],[0.361], color='red', marker=r'$x_1$', markersize=12)\n",
    "# #plt.plot([1.4],[-0.276], color='red', marker=r'$\\tilde{x}$', markersize=12)\n",
    "# plt.plot([4.94],[0.452], color='red', marker=r'$x_2$', markersize=12)\n",
    "# plt.plot(x, y, color=\"black\", label=\"h*\", linewidth=3)\n",
    "# plt.plot(x1,y1, color=\"black\", linewidth=3)\n",
    "# plt.plot(x2,y2, color=\"black\", linewidth=3)\n",
    "# plt.plot(x3,y3, color=\"black\", linewidth=3)\n",
    "# plt.plot(x4,y4, color=\"black\", linewidth=3)\n",
    "# plt.axis('off')\n",
    "# plt.title(\"x + Unsafe Directions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checking auth. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to do\n",
    "\n",
    "## CodeBase \n",
    "- \n",
    "\n",
    "## Code Refactor \n",
    "- Convert point class to torch vector and have functionality that tensors converts to numpy arrays (and check devices) for plotting \n",
    "- Modularize existing code to print all relevant plots and save relevant figures (sublevel sets at p0,p1,p2, p-til)\n",
    "- Save the data domain as a data set. with a tag of \"exact partition\"\n",
    "- Add data-generator code that fixes and samples from grid when asked for \"synthetic2D\"\n",
    "- Add data-generator code that does regular data-loading for \"MNIST, BlockMNIST, CIFAR-x, Imagenet\"\n",
    "- Add dataset-hyperparams for each. \n",
    "\n",
    "## Threat functions \n",
    "- Implement isotropic functions\n",
    "- For each point, compute unsafe directions and exact normalization. \n",
    "- Implement non-isotropic threat functions. \n",
    "\n",
    "## Synthetic2D\n",
    "- Choose synthetic h, h1, h2 and data domain. \n",
    "- Visualize data domain with points p0, p1, p2 and ptil. \n",
    "- Design class-wise marginal input distribution that are tightly concentrated. Sample 500 points for each label. \n",
    "- Find certified radius for each triple (h, x, d) w.r.t each d in distance metrics (N, approx-n, k-approx-N), each x in the data domain, and h in {h*, h1,h2} by searching over sublevel sets. \n",
    "- Visualize as intensity maps. Show variation between h1 and h2. \n",
    "\n",
    "## Observed and k-Observed\n",
    "- Compute unsafe directions with beta normalization w.r.t all sample points. Add resulting distances as observed-PL. \n",
    "- Given any data-set find k-subsets for each class using greedy approximation of cosine similarity. Add resulting distances as k-observed-PL. \n",
    "- Choose beta for normalization based on the minimal norm of all observed unsafe directions that are within a kappa threshold in cosine similarity. \n",
    "- Run through visualization and certification sequence for PL (if exact), observed-PL and k-observed-PL. \n",
    "\n",
    "## Projection\n",
    "- Given a reference point pref, a new point p, Find projection of p to sublevel set Td(pref, epsilon). \n",
    "- Use greedy projection algorithm for each non-isotropic distance. Run T rounds and then scale the iterate if it is still not in the sublevel set. \n",
    "\n",
    "## Augment\n",
    "- N-Mixup \n",
    "- N-Project\n",
    "- Visualize points added according to both on the \"synthetic2D\" dataset. \n",
    "\n",
    "## Attack and Train\n",
    "- N-PGD : Generic PGD + projection onto C set where C is specific by a N-threat function or just a simple threat function. \n",
    "- Adversarial training with N-PGD. \n",
    "- Robust Accuracy evaluation. \n",
    "- Learn tiny neural network on synthetic2D. show N-PGD attack points. \n",
    "\n",
    "## SOTA Evaluation\n",
    "- Import model weights from RobustBench and plug into existing code-base. \n",
    "- Compute robust accuracy under PGD and N-PGD attacks. Show ranking and robust accuracy curves. \n",
    "- Finetune top-5 models with N-Mixup, N-Project and N-adversarial training, show robust accuracy on all combinations and hyperparameter sweeps. \n",
    "\n",
    "\n",
    "## Certified Robustness  \n",
    "- Search over approximation of predictor intensity based on LirPA, plot histograms and certified accuracy curves. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advrob",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
